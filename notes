docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS raw_events (
    id            BIGSERIAL PRIMARY KEY,
    source        VARCHAR(32),
    title         TEXT,
    body          TEXT,
    published_at  TIMESTAMPTZ,
    url           TEXT UNIQUE,
    likes         INT,
    retweets      INT,
    collected_at  TIMESTAMPTZ DEFAULT now()
);
SQL
)"

docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS summaries (
    id          BIGSERIAL PRIMARY KEY,
    raw_id      BIGINT UNIQUE
                REFERENCES raw_events(id) ON DELETE CASCADE,
    summary_cn  TEXT          NOT NULL,
    summary_en  TEXT          NOT NULL,
    created_at  TIMESTAMPTZ   DEFAULT now()
);
SQL
)"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT id, source, left(title,50) AS title_snip, published_at
      FROM raw_events
      ORDER BY id DESC
      LIMIT 3;"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT COUNT(*) FROM summaries;"

  docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT raw_id, left(summary_cn,40) AS cn_snip,
              left(summary_en,40) AS en_snip,
              created_at
        FROM summaries
    ORDER BY created_at DESC
       LIMIT 5;"



å¦‚æœä½ æƒ³è®© æ‰€æœ‰ raw_events é‡æ–°è¿›å…¥é˜Ÿåˆ—ï¼Œåªè¦æŠŠæ•´ä¸ª summaries è¡¨æ¸…ç©ºå°±è¡Œï¼š


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "TRUNCATE TABLE summaries RESTART IDENTITY;"


  # æŸ¥çœ‹å·æ˜¯å¦å­˜åœ¨
docker volume ls | grep pgadmin-data

# è¿›å…¥å·ç›®å½•ï¼ˆLinux/macOSï¼‰
docker volume inspect pgadmin-data \
  --format '{{ .Mountpoint }}'

# å¤‡ä»½ pgAdmin é…ç½®ï¼ˆå¯é€‰ï¼‰
docker run --rm -v pgadmin-data:/data alpine \
  tar -czf - -C /data . > pgadmin_backup_$(date +%F).tgz

# X API token
AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4

curl -X GET "https://api.twitter.com/2/users/by?usernames=cnviolations,reuters,bbcworld \
  -H "Authorization: AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4"


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.reuters import ReutersScraper
scraper = ReutersScraper()
raw = scraper.fetch()
items = scraper.parse(raw)
print(f"ğŸ” Reuters fetched {len(items)} items")
for i, it in enumerate(items[:3], 1):
    print(f"\nâ€” Item {i} â€”")
    print(it)
PY


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.twitter_source import TwitterScraper
scraper = TwitterScraper()
tweets = list(scraper.fetch_all())
print(f"ğŸ” Twitter fetched {len(tweets)} tweets")
for i, tw in enumerate(tweets[:3], 1):
    print(f"\nâ€” Tweet {i} â€”")
    print(tw.as_dict())
PY
docker compose exec --user root airflow-webserver bash
echo 'export HTTP_PROXY=http://host.docker.internal:1082'  >> /root/.bashrc
echo 'export HTTPS_PROXY=http://host.docker.internal:1082' >> /root/.bashrc
exit



ç³»ç»Ÿè§’è‰²: ä½ æ˜¯ä¸€åèµ„æ·± Python åç«¯ + æ•°æ®å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ Airflowã€LLM APIã€å‘é‡æ•°æ®åº“ã€æ–‡ä»¶ I/Oã€‚

ç›®æ ‡: ä¸ºä¸­æ–‡æ—¶æ”¿è‡ªåª’ä½“æ„å»ºä¸€æ¡â€œæŠ“-åˆ†-é€‰-å†™â€è‡ªåŠ¨é€‰é¢˜æµæ°´çº¿â€”â€”  
- **ä»…æŠ“å–è¿‡å» 24 å°æ—¶çš„æ–°é—»**  
- **GPT ç”„åˆ« + å»é‡**ï¼šåŒä¸€äº‹ä»¶ä»…å†™ä¸€æ¬¡ï¼Œé™¤éåˆ¤å®šä¸ºâ€œé‡å¤§æ›´æ–°â€  
- **æ¯å¤©è¿è¡Œ 4 æ¬¡**ï¼ˆUTC+8 çš„ 00:00ã€06:00ã€12:00ã€18:00ï¼‰ï¼ŒæŠŠç¬¦åˆè¦æ±‚çš„æ‘˜è¦å†™å…¥æœ¬åœ° Markdownï¼ˆæŒ‰æ—¥æœŸèšåˆï¼‰

LANG=zh  # æ”¹æˆ en å¯åˆ‡æ¢è‹±æ–‡
====================== éœ€æ±‚è¯¦æƒ…ï¼ˆv3ï¼‰ ======================
1. **æ•°æ®é‡‡é›† (æŠ“)**
   - æ–°é—»æºï¼šNewsAPIã€EventRegistryã€Reuters RSSã€X/Twitter æŒ‡å®šè´¦å·ã€å¾®åšçƒ­æœ
   - Airflow DAG `schedule_interval="0 */6 * * *"`ï¼Œæ¯æ¬¡ä»…æ‹‰å– `now()-24h` å†…çš„æ–°æ–‡
   - ç»Ÿä¸€å­—æ®µ `id, title, body, published_at, source, url, lang, social_metrics`
2. **åˆç­› + å»é‡ (åˆ†)**
   - GPT-4o å‡½æ•°è°ƒç”¨ï¼šè¿‡æ»¤éã€Œæ”¿æ²»/å†›äº‹/ç§‘æŠ€/ç»æµ/æ–‡åŒ–ã€ã€>24hã€æ— ç‹¬å®¶ç»†èŠ‚ã€å¯¹ç›®æ ‡ç”¨æˆ·æ— ç”¨ çš„æŠ¥æ–‡  
   - **å†å²å»é‡**  
     1. å¯¹ `title+url` ç”Ÿæˆ SimHash â†’ 80 % ç›¸ä¼¼å³åŒäº‹ä»¶  
     2. è‹¥æ•°æ®åº“å·²æœ‰æ‘˜è¦ï¼Œè°ƒç”¨ GPT è¯¢é—® _â€œæ˜¯å¦é‡å¤§æ›´æ–°ï¼Ÿï¼ˆæ˜¯/å¦ + 20 å­—ç†ç”±ï¼‰â€_  
        - å¦ â†’ ä¸¢å¼ƒ  
        - æ˜¯ â†’ è§†ä¸ºæ–°æ‘˜è¦ï¼Œå†™å…¥å¹¶åœ¨ Markdown å¡ç‰‡æ ‡æ³¨â€œã€æ›´æ–°ã€‘â€
3. **é‡åŒ–æ‰“åˆ† (åˆ¤)**
   - å…¬å¼ `score = 0.4*Hot + 0.4*Sim + 0.2*Fresh`  
   - `Hot` = likes + retweets  
   - `Sim` = ä¸"æ—¶æ”¿è§†é¢‘è´¦å·ä¸»é¢˜å‘é‡"ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆFaissï¼‰  
   - `Fresh` = e^(â€“Î”t/24h)  
   - `score > 0.6` å…¥æ± 
4. **æ‘˜è¦ç”Ÿæˆ (å†™)**
   - GPT-4o Few-shot Promptï¼Œè¾“å‡º **JSON**ï¼š
     ```json
     {
       "hashtags": ["#å›½å®¶", "#è®®é¢˜"],   // 2-5 ä¸ª#
       "title": "â‰¤8 å­—ä¸»æ ‡é¢˜",
       "subtitle": "â‰¤12 å­—å‰¯æ ‡é¢˜",
       "summary": "â‘  äº‹ä»¶â€¦â‘¡ èƒŒæ™¯â€¦â‘¢ çœ‹ç‚¹â€¦", // â‰¤200 å­—
       "date": "YYYY-MM-DD",
       "source": "åª’ä½“ â€“ URL",
       "is_update": false           // GPT åˆ¤æ–­çš„é‡å¤§æ›´æ–°æ ‡è®°
     }
     ```
5. **æœ¬åœ°è½ç›˜ (è¾“å‡º)**
   - è·¯å¾„ `./summaries/YYYY-MM-DD.md`ï¼Œæ¯æ—¥å•æ–‡ä»¶ï¼›è‹¥å·²å­˜åœ¨åˆ™è¿½åŠ   
   - Markdown æ¨¡æ¿ï¼š
     ```markdown
     ## {title}ï½œ{subtitle}{% if is_update %}ã€æ›´æ–°ã€‘{% endif %}
     - **{hashtags}**
     - â‘  â€¦ â‘¡ â€¦ â‘¢ â€¦
     - *æ¥æºï¼š{source}*
     ```
   - ç¼–ç  UTF-8ï¼Œæ—  BOM
6. **è¿è¡Œé¢‘æ¬¡**  
   - Airflow DAG `news_pipeline.py`ï¼š`0 */6 * * *`ï¼ˆåŒ—äº¬æ—¶é—´ 00/06/12/18 ç‚¹è§¦å‘ï¼‰

æŠ€æœ¯æ ˆ
-------
- **Python 3.11** ï¼ˆpoetry ç®¡ç†ä¾èµ–ï¼‰  
- Airflow 2.9  
- HTTP: httpx + tenacity é‡è¯•  
- OpenAI SDK â‰¥1.30ï¼ˆå‡½æ•°è°ƒç”¨ï¼‰  
- å‘é‡åº“: faiss-cpu  
- åˆ¤é‡: simhash + Redis Bloom  
- ORM: SQLModel + SQLiteï¼ˆæœ¬åœ°ï¼Œå¯æ›¿æ¢ Postgresï¼‰  
- å•å…ƒæµ‹è¯•: pytest + GitHub Actions CI  

äº¤ä»˜ç‰©
------
1. **ç›®å½•ç»“æ„**

```
ç°åœ¨æ‚¨å¯ä»¥é€šè¿‡pgAdminè¿æ¥V2æ•°æ®åº“ï¼š
è¿æ¥å‚æ•°ï¼š
ä¸»æœº: host.docker.internal
ç«¯å£: 5434
æ•°æ®åº“: ainews
ç”¨æˆ·å: airflow
å¯†ç : airflow_pass

è®¿é—® Phoenix Airflow UI: http://localhost:8082
ç™»å½•å‡­æ®:
ç”¨æˆ·å: phoenix_admin
å¯†ç : phoenix123
åœ¨ Phoenix UI ä¸­æ‰‹åŠ¨è§¦å‘ DAG:
æ‰¾åˆ° phoenix_news_pipeline DAG
ç‚¹å‡» "Trigger DAG" æŒ‰é’®

Phoenix æ•°æ®åº“è¿æ¥å‚æ•°ï¼š
å‚æ•°	å€¼
Host	localhost
Port	5434
Database	phoenix_db
Username	phoenix_user
Password	phoenix_pass

ä½¿ç”¨æ–¹å¼
åœ¨ Airflow UI ä¸­è®¾ç½® API Keysï¼š
ç™»å½• Airflow UI
å¯¼èˆªåˆ° "Admin" -> "Variables"
åˆ›å»ºå˜é‡ ainews_eventregistry_apikeysï¼Œå€¼ä¸º JSON æ ¼å¼ï¼š




ç¬¬ä¸€æ­¥ï¼šé¢„è§ˆå°†è¦åˆ é™¤çš„æ•°æ®ï¼ˆå®‰å…¨æ£€æŸ¥ï¼‰
è¯·å…ˆå¤åˆ¶å¹¶æ‰§è¡Œä»¥ä¸‹ SQL å‘½ä»¤ã€‚è¿™ä¸ªå‘½ä»¤ä¸ä¼šåˆ é™¤ä»»ä½•æ•°æ®ï¼Œåªä¼šæŠŠæ»¡è¶³æ¡ä»¶ï¼ˆåœ¨åŒ—äº¬æ—¶é—´2025å¹´8æœˆ5æ—¥é‡‡é›†ï¼‰çš„è®°å½•å…¨éƒ¨åˆ—å‡ºæ¥ç»™æ‚¨çœ‹ã€‚

SQL

SELECT *
FROM public.raw_events
WHERE
    collected_at::date = '2025-08-05';
æ‰§è¡Œåï¼Œè¯·æ£€æŸ¥è¿”å›çš„ç»“æœæ˜¯å¦ç¡®å®æ˜¯æ‚¨æƒ³è¦åˆ é™¤çš„ã€collected_at æ—¥æœŸä¸º 2025å¹´8æœˆ5æ—¥ çš„æ‰€æœ‰è®°å½•ã€‚

ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œåˆ é™¤æ“ä½œ
åœ¨æ‚¨ç¡®è®¤ç¬¬ä¸€æ­¥é¢„è§ˆçš„æ•°æ®æ— è¯¯åï¼Œå†æ‰§è¡Œä¸‹é¢çš„ DELETE å‘½ä»¤æ¥çœŸæ­£åœ°åˆ é™¤è¿™äº›æ•°æ®ã€‚

SQL

DELETE
FROM public.raw_events
WHERE
    collected_at::date = '2025-08-05';


[
  "http://en.wikipedia.org/wiki/Gaza_Strip",
  "http://en.wikipedia.org/wiki/Israelâ€“Hamas_war",
  "http://en.wikipedia.org/wiki/Russo-Ukrainian_War",
  "http://en.wikipedia.org/wiki/Russian_invasion_of_Ukraine",
  "http://en.wikipedia.org/wiki/Russiaâ€“Ukraine_border",
  "http://en.wikipedia.org/wiki/Russiaâ€“Ukraine_war",
  "http://en.wikipedia.org/wiki/Russiaâ€“Ukraine_relations",
  "http://en.wikipedia.org/wiki/Gaza_City", 
  "http://en.wikipedia.org/wiki/Hamas"
  "	http://en.wikipedia.org/wiki/Fatahâ€“Hamas_conflict"
  "http://en.wikipedia.org/wiki/Israeliâ€“Palestinian_conflict"
  "http://en.wikipedia.org/wiki/West_Bank"
  "http://en.wikipedia.org/wiki/Palestinians"
  "http://en.wikipedia.org/wiki/Palestine"
  "http://en.wikipedia.org/wiki/Palestinian_nationalism"
]

é‡å¯ Airflow å®¹å™¨ï¼Œæ¸…æ‰ Python æ¨¡å—ç¼“å­˜ï¼Œç¡®ä¿åŠ è½½æ–°ä»£ç 
é‡å¯ webserver ä¸ schedulerï¼š
docker-compose -f docker-compose.phoenix.yml restart phoenix-webserver phoenix-scheduler
å¦‚ä»ç¼“å­˜æ—§ä»£ç ï¼Œè¯·é‡å»ºé•œåƒå¹¶å¯åŠ¨ï¼š
docker-compose -f docker-compose.phoenix.yml build --no-cache phoenix-webserver phoenix-scheduler
docker-compose -f docker-compose.phoenix.yml up -d phoenix-webserver phoenix-scheduler

# ====================== Milestone 2: Phoenix â†’ Gemini å‡çº§è„šæ‰‹æ¶æ­å»º ======================

## ä»»åŠ¡ç†è§£ä¸æ‰§è¡Œæ–¹æ¡ˆè¯¦ç»†é˜è¿°

### 1. ä»»åŠ¡ç›®æ ‡
ä¸º Phoenix â†’ Gemini å‡çº§æ­å»ºå®Œæ•´çš„è„šæ‰‹æ¶ï¼ŒåŒ…æ‹¬ï¼š
- Gemini ä¸“å±ç›®å½•ç»“æ„
- é™æ€é…ç½®æ–‡ä»¶ï¼ˆprompts/schema/filtersï¼‰
- å ä½ç¬¦æ¨¡å—ï¼ˆvalidators/renderersï¼‰
- ç»Ÿä¸€é…ç½®è¯»å–å·¥å…·
- éªŒè¯è„šæœ¬

### 2. è®¾è®¡åŸåˆ™
- **åˆ†ç¦»åŸåˆ™**ï¼šGemini ç›®å½•ä¸ Phoenix ä¸»é“¾å®Œå…¨åˆ†ç¦»
- **é™æ€åŒ–**ï¼šæ‰€æœ‰æ¨¡æ¿/Schema/è¯è¡¨å‡ä¸ºé™æ€æ–‡ä»¶ï¼Œé¿å…ç¡¬ç¼–ç 
- **é…ç½®åŒ–**ï¼šæ”¯æŒ Airflow Variables å’Œç¯å¢ƒå˜é‡é…ç½®
- **å‘åå…¼å®¹**ï¼šä¸å½±å“ç°æœ‰ Phoenix æµç¨‹

### 3. æ‰§è¡Œæ–¹æ¡ˆé€ç‚¹è¯´æ˜

#### 3.1 ç›®å½•ç»“æ„åˆ›å»º
```
dags/gemini/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ system_instruction.md
â”‚   â”œâ”€â”€ response_schema.json
â”‚   â”œâ”€â”€ select_top_schema.json
â”‚   â””â”€â”€ md_template.md.j2
â”œâ”€â”€ validators.py
â”œâ”€â”€ renderers.py
â””â”€â”€ config_reader.py

configs/filters/
â”œâ”€â”€ normal_conflict.json
â””â”€â”€ bang_words.json

dev/
â””â”€â”€ verify_gemini_setup.py
```

#### 3.2 é™æ€é…ç½®æ–‡ä»¶è®¾è®¡
- **system_instruction.md**ï¼šAI é€‰é¢˜ç¼–è¾‘æ‰‹å†Œï¼ŒåŒ…å«å®Œæ•´è§„åˆ™
- **response_schema.json**ï¼šæœ€ç»ˆé€‰é¢˜å¡ç‰‡çš„ JSON Schema
- **select_top_schema.json**ï¼šç¬¬ä¸€é˜¶æ®µé€‰ Top10 çš„ Schema
- **md_template.md.j2**ï¼šJinja2 æ¨¡æ¿ï¼Œç”¨äºç”Ÿæˆ Markdown æŠ¥å‘Š
- **normal_conflict.json**ï¼šå¸¸æ€å†²çªè¯è¡¨
- **bang_words.json**ï¼šçˆ†ç‚¹è¯è¡¨

#### 3.3 å ä½ç¬¦æ¨¡å—è®¾è®¡
- **validators.py**ï¼šåŒ…å« `validate_cards()` å‡½æ•°å ä½ç¬¦
- **renderers.py**ï¼šåŒ…å« `render_markdown()` å‡½æ•°å ä½ç¬¦
- **config_reader.py**ï¼šç»Ÿä¸€é…ç½®è¯»å–å·¥å…·ï¼Œæ”¯æŒ Airflow Variables å’Œç¯å¢ƒå˜é‡

#### 3.4 Airflow Variables é…ç½®
éœ€è¦é…ç½® 10 ä¸ª Airflow Variablesï¼š
- è·¯å¾„é…ç½®ï¼šphoenix_exports_dir, gemini_outputs_dir
- è°ƒåº¦é…ç½®ï¼šgemini_dag_schedule, email_dag_schedule
- æ–‡ä»¶è·¯å¾„ï¼šgemini_system_instruction_path, gemini_response_schema_path ç­‰
- è¿‡æ»¤é…ç½®ï¼šfilter_normal_conflict_path, filter_bang_words_path
- é‚®ä»¶é…ç½®ï¼šrecipient_email_list

#### 3.5 é…ç½®è¯»å–é€»è¾‘
- ä¼˜å…ˆä» Airflow Variables è¯»å–
- å¤±è´¥æ—¶ä»ç¯å¢ƒå˜é‡è¯»å–
- æœ€åä½¿ç”¨é»˜è®¤è·¯å¾„
- æ”¯æŒ JSON å’Œ Markdown æ–‡ä»¶åŠ è½½

#### 3.6 éªŒè¯æœºåˆ¶
- æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- éªŒè¯ Airflow Variables é…ç½®
- æµ‹è¯•å ä½ç¬¦æ¨¡å—å¯¼å…¥
- ç¡®ä¿é…ç½®è¯»å–åŠŸèƒ½æ­£å¸¸

### 4. å®ç°ç»†èŠ‚

#### 4.1 æ–‡ä»¶å†…å®¹è®¾è®¡
- æ‰€æœ‰é…ç½®æ–‡ä»¶ä½¿ç”¨æ ‡å‡†æ ¼å¼ï¼ˆJSON/Markdown/Jinja2ï¼‰
- å†…å®¹åŸºäºå®é™…ä¸šåŠ¡éœ€æ±‚è®¾è®¡
- ç¡®ä¿æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¯è¢«ç›¸åº”å·¥å…·è§£æ

#### 4.2 è·¯å¾„ç®¡ç†
- ä½¿ç”¨ç»å¯¹è·¯å¾„é…ç½®
- æ”¯æŒç¯å¢ƒå˜é‡å’Œ Airflow Variables çš„çµæ´»é…ç½®
- é›†ä¸­ç®¡ç†ï¼Œä¾¿äºç»´æŠ¤

#### 4.3 é”™è¯¯å¤„ç†
- é…ç½®è¯»å–å¤±è´¥æ—¶çš„ä¼˜é›…é™çº§
- æ–‡ä»¶ä¸å­˜åœ¨æ—¶çš„é»˜è®¤è¡Œä¸º
- ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

### 5. éªŒè¯æ ‡å‡†
- ç›®å½•ç»“æ„ä¸æ–‡ä»¶å…¨éƒ¨å­˜åœ¨
- config_reader.py èƒ½æ­£ç¡®è¯»å–æ–‡ä»¶
- validators.pyã€renderers.py å¯è¢«æ­£å¸¸å¯¼å…¥
- verify_gemini_setup.py èƒ½è¿è¡Œå¹¶éªŒè¯æ‰€æœ‰ç»„ä»¶
- Phoenix ä¸»é“¾è¿è¡Œä¸å—å½±å“

## å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨ä¸å…³é”®ä»£ç æ®µ

### æ–°å»ºæ–‡ä»¶åˆ—è¡¨ï¼š
1. `dags/gemini/__init__.py` - Gemini åŒ…åˆå§‹åŒ–
2. `dags/gemini/prompts/system_instruction.md` - AI é€‰é¢˜ç¼–è¾‘æ‰‹å†Œ
3. `dags/gemini/prompts/response_schema.json` - å“åº” Schema å®šä¹‰
4. `dags/gemini/prompts/select_top_schema.json` - é€‰ Top Schema å®šä¹‰
5. `dags/gemini/prompts/md_template.md.j2` - Markdown æ¨¡æ¿
6. `configs/filters/normal_conflict.json` - å¸¸æ€å†²çªè¯è¡¨
7. `configs/filters/bang_words.json` - çˆ†ç‚¹è¯è¡¨
8. `dags/gemini/validators.py` - éªŒè¯å™¨å ä½ç¬¦
9. `dags/gemini/renderers.py` - æ¸²æŸ“å™¨å ä½ç¬¦
10. `dags/gemini/config_reader.py` - é…ç½®è¯»å–å·¥å…·
11. `dev/verify_gemini_setup.py` - éªŒè¯è„šæœ¬

### å…³é”®ä»£ç æ®µé¢„è§ˆï¼š

#### `dags/gemini/config_reader.py`
```python
from typing import Any
import json, os

def get_config_path(var_name: str, default_path: str) -> str:
    """ä¼˜å…ˆä» Airflow Variables è¯»å–è·¯å¾„ï¼Œå¤±è´¥æ—¶å›é€€åˆ°é»˜è®¤è·¯å¾„ã€‚"""
    try:
        from airflow.models import Variable
        return Variable.get(var_name, default_var=default_path)
    except Exception:
        return os.getenv(var_name.upper(), default_path)

def load_json_config(path: str) -> Any:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def load_markdown_template(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()
```

#### `dags/gemini/validators.py`
```python
def validate_cards(cards: list[dict]) -> list[dict]:
    """å ä½å‡½æ•°ï¼šæœªæ¥å®ç°å­—æ®µæ ¡éªŒä¸ä¿®å¤é€»è¾‘ã€‚å½“å‰ç›´æ¥è¿”å›åŸè¾“å…¥ã€‚"""
    return cards
```

#### `dags/gemini/renderers.py`
```python
def render_markdown(cards: list[dict], template_path: str) -> str:
    """å ä½å‡½æ•°ï¼šæœªæ¥å®ç° Markdown æ¸²æŸ“é€»è¾‘ã€‚å½“å‰è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚"""
    return ""
```

#### `dev/verify_gemini_setup.py`
```python
import os
from dags.gemini import validators, renderers, config_reader

def main():
    print("Checking Gemini setup...")
    
    required_files = [
        os.getenv("gemini_system_instruction_path"),
        os.getenv("gemini_response_schema_path"),
        os.getenv("gemini_select_top_schema_path"),
        os.getenv("gemini_md_template_path"),
        os.getenv("filter_normal_conflict_path"),
        os.getenv("filter_bang_words_path"),
    ]
    
    for f in required_files:
        if not f or not os.path.exists(f):
            print(f"âŒ Missing file: {f}")
        else:
            print(f"âœ… Found: {f}")
    
    try:
        print("âœ… validators:", validators.validate_cards([]))
        print("âœ… renderers:", renderers.render_markdown([], ""))
        print("âœ… config_reader OK")
    except Exception as e:
        print("âŒ Import test failed:", e)

if __name__ == "__main__":
    main()
```

## å¾…ç¡®è®¤åå¼€å§‹å®æ–½

ä»¥ä¸Šæ˜¯è¯¦ç»†çš„æ‰§è¡Œæ–¹æ¡ˆï¼Œå·²è®°å½•åˆ° notes æ–‡ä»¶ä¸­ã€‚è¯·ç¡®è®¤ï¼š

1. **ç›®å½•ç»“æ„è®¾è®¡**æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Ÿ
2. **æ–‡ä»¶å†…å®¹è®¾è®¡**æ˜¯å¦æ»¡è¶³ä¸šåŠ¡éœ€æ±‚ï¼Ÿ
3. **Airflow Variables é…ç½®**æ˜¯å¦å®Œæ•´ï¼Ÿ
4. **å®ç°æ–¹æ¡ˆ**æ˜¯å¦æœ‰é—æ¼æˆ–éœ€è¦è°ƒæ•´çš„åœ°æ–¹ï¼Ÿ

ç¡®è®¤æ— è¯¯åï¼Œæˆ‘å°†ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ–¹æ¡ˆå¼€å§‹å®æ–½ï¼Œç¡®ä¿ï¼š
- ä¸¥æ ¼æ‰§è¡Œå·²ç¡®å®šçš„æ–¹æ¡ˆ
- å¦‚é‡é—®é¢˜ä¸ç»•å¼€ï¼Œå…ˆä¸æ‚¨ç¡®è®¤
- ç¡®ä¿ç°æœ‰ Phoenix æµç¨‹ä¸å—å½±å“
- æ‰€æœ‰æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¯è¢«æ­£å¸¸ä½¿ç”¨

è¯·ç¡®è®¤æ˜¯å¦å¯ä»¥å¼€å§‹å®æ–½ï¼Ÿ

# ====================== Milestone 3 ä¿®æ­£è¯´æ˜ ======================

## ä¿®æ­£è¦ç‚¹

### ä¸€è‡´éƒ¨åˆ†ï¼ˆä¿æŒä¸å˜ï¼‰
- DAG IDï¼š`gemini_card_generation_dag`
- è°ƒåº¦æ—¶é—´ï¼š06:00 BJTï¼ˆAirflow Variable: `gemini_dag_schedule`ï¼‰
- ä»»åŠ¡é“¾ï¼š`find_input â†’ pre_filter â†’ select_top10 â†’ write_cards â†’ validate_and_fix â†’ render_markdown â†’ save_metrics`
- è¾“å…¥/è¾“å‡ºæ–‡ä»¶é€»è¾‘ã€æ–‡ä»¶å‘½åè§„åˆ™ã€æ ¡éªŒé€»è¾‘ã€æ¸²æŸ“é€»è¾‘ã€metrics ä¿å­˜æœºåˆ¶
- å¤ç”¨çš„æ¨¡å—ï¼š`dags/phoenix/time_utils.py`ã€`dags/gemini/validators.py`ã€`dags/gemini/renderers.py`ã€`dags/gemini/config_reader.py`
- æ–°å¢ Airflow Variablesï¼š`gemini_model_id`ã€`summary_truncate_chars`ã€`cards_topk`

### å¿…é¡»ä¿®æ”¹çš„åœ°æ–¹

#### å¯¼å…¥éƒ¨åˆ†ä¿®æ­£
**âŒ é”™è¯¯å†™æ³•ï¼ˆä¸è¦ç”¨ï¼‰**ï¼š
```python
from dags.gemini.config_reader import get_gemini_config_paths, load_gemini_configs
```

**âœ… æ­£ç¡®å†™æ³•ï¼ˆæŒ‰ç…§æ–¹æ¡ˆé€‰é¡¹ Aï¼‰**ï¼š
```python
from dags.gemini.config_reader import (
    get_config_path,
    load_json_config,
    load_markdown_template
)
```

#### è°ƒç”¨æ–¹å¼ä¿®æ­£
**åœ¨ DAG å†…ç›´æ¥è°ƒç”¨è¿™äº›å·¥å…·å‡½æ•°**ï¼š
```python
# è·å–é…ç½®è·¯å¾„
schema_path = get_config_path("gemini_response_schema_path", "/opt/airflow/dags/gemini/prompts/response_schema.json")
response_schema = load_json_config(schema_path)

template_path = get_config_path("gemini_md_template_path", "/opt/airflow/dags/gemini/prompts/md_template.md.j2")
template_str = load_markdown_template(template_path)

# å…¶ä»–é…ç½®ç¤ºä¾‹
system_instruction_path = get_config_path("gemini_system_instruction_path", "/opt/airflow/dags/gemini/prompts/system_instruction.md")
system_instruction = load_markdown_template(system_instruction_path)

select_top_schema_path = get_config_path("gemini_select_top_schema_path", "/opt/airflow/dags/gemini/prompts/select_top_schema.json")
select_top_schema = load_json_config(select_top_schema_path)

normal_conflict_path = get_config_path("filter_normal_conflict_path", "/opt/airflow/configs/filters/normal_conflict.json")
normal_conflict_words = load_json_config(normal_conflict_path)

bang_words_path = get_config_path("filter_bang_words_path", "/opt/airflow/configs/filters/bang_words.json")
bang_words = load_json_config(bang_words_path)
```

#### é‡è¦çº¦æŸ
âš ï¸ **ä¸è¦æ–°å¢** `get_gemini_config_paths` æˆ– `load_gemini_configs` å‡½æ•°åˆ° `config_reader.py`
âš ï¸ **ä¿æŒæ–‡ä»¶åŸçŠ¶**ï¼Œåªç”¨ç°æœ‰çš„ä¸‰ä¸ªå‡½æ•°ï¼š`get_config_path`ã€`load_json_config`ã€`load_markdown_template`

## ä¿®æ­£åçš„æ‰§è¡Œæ–¹æ¡ˆ

### 1. æ–‡ä»¶ç»“æ„è®¾è®¡

**æ–°å»ºæ–‡ä»¶**ï¼š
- `dags/gemini/gemini_card_generation_dag.py` - ä¸» DAG æ–‡ä»¶

**ä¿®æ”¹æ–‡ä»¶**ï¼š
- `dags/gemini/validators.py` - æ‰©å±•æ ¡éªŒé€»è¾‘
- `dags/gemini/renderers.py` - æ‰©å±•æ¸²æŸ“é€»è¾‘ï¼Œæ”¯æŒ Jinja2

**è°ƒç”¨å·²æœ‰æ¨¡å—**ï¼š
- `dags/phoenix/time_utils.py` - é€»è¾‘æ—¥æœŸè®¡ç®—
- `dags/gemini/config_reader.py` - é…ç½®è¯»å–ï¼ˆä»…ä½¿ç”¨ç°æœ‰ä¸‰ä¸ªå‡½æ•°ï¼‰

### 2. å…³é”®å®ç°ç»†èŠ‚

#### 2.1 å¯¼å…¥éƒ¨åˆ†
```python
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from dags.phoenix.time_utils import prev_logical_date_str
from dags.gemini.config_reader import (
    get_config_path,
    load_json_config,
    load_markdown_template
)
from dags.gemini.validators import validate_cards
from dags.gemini.renderers import render_markdown
```

#### 2.2 é…ç½®è¯»å–æ–¹å¼
```python
def load_all_configs():
    """åŠ è½½æ‰€æœ‰å¿…éœ€çš„é…ç½®æ–‡ä»¶"""
    configs = {}
    
    # ç³»ç»ŸæŒ‡ä»¤
    system_instruction_path = get_config_path(
        "gemini_system_instruction_path", 
        "/opt/airflow/dags/gemini/prompts/system_instruction.md"
    )
    configs['system_instruction'] = load_markdown_template(system_instruction_path)
    
    # å“åº” Schema
    response_schema_path = get_config_path(
        "gemini_response_schema_path", 
        "/opt/airflow/dags/gemini/prompts/response_schema.json"
    )
    configs['response_schema'] = load_json_config(response_schema_path)
    
    # é€‰ Top Schema
    select_top_schema_path = get_config_path(
        "gemini_select_top_schema_path", 
        "/opt/airflow/dags/gemini/prompts/select_top_schema.json"
    )
    configs['select_top_schema'] = load_json_config(select_top_schema_path)
    
    # Markdown æ¨¡æ¿
    md_template_path = get_config_path(
        "gemini_md_template_path", 
        "/opt/airflow/dags/gemini/prompts/md_template.md.j2"
    )
    configs['md_template'] = load_markdown_template(md_template_path)
    
    # è¿‡æ»¤è¯è¡¨
    normal_conflict_path = get_config_path(
        "filter_normal_conflict_path", 
        "/opt/airflow/configs/filters/normal_conflict.json"
    )
    configs['normal_conflict'] = load_json_config(normal_conflict_path)
    
    bang_words_path = get_config_path(
        "filter_bang_words_path", 
        "/opt/airflow/configs/filters/bang_words.json"
    )
    configs['bang_words'] = load_json_config(bang_words_path)
    
    return configs
```

#### 2.3 ä»»åŠ¡å®ç°ç¤ºä¾‹
```python
def pre_filter_articles(**context):
    """é¢„è¿‡æ»¤æ–‡ç« """
    # è·å–é…ç½®
    normal_conflict_path = get_config_path(
        "filter_normal_conflict_path", 
        "/opt/airflow/configs/filters/normal_conflict.json"
    )
    normal_conflict_words = load_json_config(normal_conflict_path)
    
    bang_words_path = get_config_path(
        "filter_bang_words_path", 
        "/opt/airflow/configs/filters/bang_words.json"
    )
    bang_words = load_json_config(bang_words_path)
    
    # å®ç°è¿‡æ»¤é€»è¾‘
    # ...

def select_top10(**context):
    """é€‰æ‹© Top10 æ–‡ç« """
    # è·å–é…ç½®
    system_instruction_path = get_config_path(
        "gemini_system_instruction_path", 
        "/opt/airflow/dags/gemini/prompts/system_instruction.md"
    )
    system_instruction = load_markdown_template(system_instruction_path)
    
    select_top_schema_path = get_config_path(
        "gemini_select_top_schema_path", 
        "/opt/airflow/dags/gemini/prompts/select_top_schema.json"
    )
    select_top_schema = load_json_config(select_top_schema_path)
    
    # å®ç°é€‰æ‹©é€»è¾‘
    # ...

def write_cards(**context):
    """ç”Ÿæˆé€‰é¢˜å¡ç‰‡"""
    # è·å–é…ç½®
    response_schema_path = get_config_path(
        "gemini_response_schema_path", 
        "/opt/airflow/dags/gemini/prompts/response_schema.json"
    )
    response_schema = load_json_config(response_schema_path)
    
    # å®ç°å¡ç‰‡ç”Ÿæˆé€»è¾‘
    # ...

def render_markdown_report(**context):
    """æ¸²æŸ“ Markdown æŠ¥å‘Š"""
    # è·å–é…ç½®
    md_template_path = get_config_path(
        "gemini_md_template_path", 
        "/opt/airflow/dags/gemini/prompts/md_template.md.j2"
    )
    template_str = load_markdown_template(md_template_path)
    
    # å®ç°æ¸²æŸ“é€»è¾‘
    # ...
```

### 3. å®Œæ•´ DAG ç»“æ„

```python
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from dags.phoenix.time_utils import prev_logical_date_str
from dags.gemini.config_reader import (
    get_config_path,
    load_json_config,
    load_markdown_template
)
from dags.gemini.validators import validate_cards
from dags.gemini.renderers import render_markdown

default_args = {
    'owner': 'phoenix-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'gemini_card_generation_dag',
    default_args=default_args,
    description='Gemini é€‰é¢˜å¡ç‰‡ç”Ÿæˆ DAG',
    schedule_interval=Variable.get("gemini_dag_schedule", default_var="0 22 * * *"),  # ä» Airflow Variable è¯»å–
    catchup=False,
    tags=['gemini', 'news', 'cards']
)

def find_input_file(**context):
    """æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶"""
    # è·å–å¯é…ç½®çš„æ—¥ç•Œ
    try:
        from airflow.models import Variable
        cutoff_hour = get_cutoff_hour(lambda k: Variable.get(k, default_var=None))
    except Exception:
        cutoff_hour = get_cutoff_hour()
    
    # ä½¿ç”¨ time_utils è®¡ç®—é€»è¾‘æ—¥æœŸï¼ˆæ”¯æŒå¯é…ç½®æ—¥ç•Œï¼‰
    run_dt_utc = context['execution_date']
    logical_date = prev_logical_date_str(run_dt_utc, cutoff_hour=cutoff_hour)
    
    # æŸ¥æ‰¾ Phoenix æ‘˜è¦æ–‡ä»¶
    phoenix_exports_dir = get_config_path("phoenix_exports_dir", "/opt/airflow/exports")
    # æ”¯æŒå›é€€æœºåˆ¶
    pass

def pre_filter_articles(**context):
    """é¢„è¿‡æ»¤æ–‡ç« """
    # ä½¿ç”¨ get_config_path å’Œ load_json_config åŠ è½½è¿‡æ»¤è¯è¡¨
    # å®ç°æ—¶é—´çª—ã€å†²çªè¯ã€å»é‡ã€æˆªæ–­é€»è¾‘
    pass

def select_top10(**context):
    """é€‰æ‹© Top10 æ–‡ç« """
    # ä½¿ç”¨ get_config_path å’Œ load_markdown_template åŠ è½½ç³»ç»ŸæŒ‡ä»¤
    # ä½¿ç”¨ get_config_path å’Œ load_json_config åŠ è½½ select_top_schema
    # è°ƒç”¨ Gemini API
    pass

def write_cards(**context):
    """ç”Ÿæˆé€‰é¢˜å¡ç‰‡"""
    # ä½¿ç”¨ get_config_path å’Œ load_json_config åŠ è½½ response_schema
    # è°ƒç”¨ Gemini API ç”Ÿæˆå®Œæ•´å¡ç‰‡
    pass

def validate_and_fix(**context):
    """æ ¡éªŒå’Œä¿®å¤å¡ç‰‡"""
    # è°ƒç”¨ validators.validate_cards
    # å®ç°æ ¡éªŒå’Œä¿®å¤é€»è¾‘
    pass

def render_markdown_report(**context):
    """æ¸²æŸ“ Markdown æŠ¥å‘Š"""
    # ä½¿ç”¨ get_config_path å’Œ load_markdown_template åŠ è½½æ¨¡æ¿
    # è°ƒç”¨ renderers.render_markdown
    pass

def save_metrics(**context):
    """ä¿å­˜è¿è¡ŒæŒ‡æ ‡"""
    # ä¿å­˜è¿è¡ŒæŒ‡æ ‡åˆ° JSON æ–‡ä»¶
    pass

# ä»»åŠ¡å®šä¹‰
find_input_task = PythonOperator(
    task_id='find_input',
    python_callable=find_input_file,
    dag=dag
)

pre_filter_task = PythonOperator(
    task_id='pre_filter',
    python_callable=pre_filter_articles,
    dag=dag
)

select_top10_task = PythonOperator(
    task_id='select_top10',
    python_callable=select_top10,
    dag=dag
)

write_cards_task = PythonOperator(
    task_id='write_cards',
    python_callable=write_cards,
    dag=dag
)

validate_task = PythonOperator(
    task_id='validate_and_fix',
    python_callable=validate_and_fix,
    dag=dag
)

render_task = PythonOperator(
    task_id='render_markdown',
    python_callable=render_markdown_report,
    dag=dag
)

save_metrics_task = PythonOperator(
    task_id='save_metrics',
    python_callable=save_metrics,
    dag=dag
)

# ä»»åŠ¡ä¾èµ–
find_input_task >> pre_filter_task >> select_top10_task >> write_cards_task >> validate_task >> render_task >> save_metrics_task
```

## å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨ä¸å…³é”®ä»£ç æ®µ

### æ–°å»ºæ–‡ä»¶ï¼š
1. `dags/gemini/gemini_card_generation_dag.py` - ä¸» DAG æ–‡ä»¶

### ä¿®æ”¹æ–‡ä»¶ï¼š
1. `dags/gemini/validators.py` - æ‰©å±•æ ¡éªŒé€»è¾‘
2. `dags/gemini/renderers.py` - æ‰©å±•æ¸²æŸ“é€»è¾‘

### å…³é”®ä»£ç æ®µï¼š

#### å¯¼å…¥éƒ¨åˆ†ï¼ˆä¿®æ­£åï¼‰
```python
from dags.gemini.config_reader import (
    get_config_path,
    load_json_config,
    load_markdown_template
)
```

#### é…ç½®è¯»å–ç¤ºä¾‹
```python
# è·å–ç³»ç»ŸæŒ‡ä»¤
system_instruction_path = get_config_path("gemini_system_instruction_path", "/opt/airflow/dags/gemini/prompts/system_instruction.md")
system_instruction = load_markdown_template(system_instruction_path)

# è·å–å“åº” Schema
response_schema_path = get_config_path("gemini_response_schema_path", "/opt/airflow/dags/gemini/prompts/response_schema.json")
response_schema = load_json_config(response_schema_path)

# è·å–æ¨¡æ¿
template_path = get_config_path("gemini_md_template_path", "/opt/airflow/dags/gemini/prompts/md_template.md.j2")
template_str = load_markdown_template(template_path)
```

## å¾…ç¡®è®¤åå¼€å§‹å®æ–½

ä»¥ä¸Šæ˜¯ä¿®æ­£åçš„æ‰§è¡Œæ–¹æ¡ˆï¼Œå·²å®Œæ•´è®°å½•åˆ° notes æ–‡ä»¶ä¸­ã€‚è¯·ç¡®è®¤ï¼š

1. **å¯¼å…¥æ–¹å¼**æ˜¯å¦æ­£ç¡®ï¼ˆä»…ä½¿ç”¨ç°æœ‰çš„ä¸‰ä¸ªå‡½æ•°ï¼‰ï¼Ÿ
2. **é…ç½®è¯»å–æ–¹å¼**æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Ÿ
3. **å®ç°ç»†èŠ‚**æ˜¯å¦æœ‰é—æ¼ï¼Ÿ
4. **ä¿®æ­£å†…å®¹**æ˜¯å¦å®Œæ•´ï¼Ÿ

ç¡®è®¤æ— è¯¯åï¼Œæˆ‘å°†ä¸¥æ ¼æŒ‰ç…§ä¿®æ­£åçš„æ–¹æ¡ˆå¼€å§‹å®æ–½ï¼Œç¡®ä¿ï¼š
- ä¸¥æ ¼æ‰§è¡Œå·²ç¡®å®šçš„æ–¹æ¡ˆ
- å¦‚é‡é—®é¢˜ä¸ç»•å¼€ï¼Œå…ˆä¸æ‚¨ç¡®è®¤
- ç¡®ä¿ç°æœ‰ Phoenix æµç¨‹ä¸å—å½±å“
- æ‰€æœ‰åŠŸèƒ½æŒ‰è®¾è®¡å®ç°

è¯·ç¡®è®¤æ˜¯å¦å¯ä»¥å¼€å§‹å®æ–½ï¼Ÿ

# ====================== Milestone 3 å¾®è°ƒè¯´æ˜ ======================

## å¿…é¡»åŒæ­¥çš„å¾®è°ƒ

### 1. ä¿®æ­£é¢„è§ˆä»£ç é‡Œçš„å¯¼å…¥ï¼ˆå·²ä¿®æ­£ï¼‰
**âŒ æ—§å†™æ³•**ï¼š
```python
from dags.gemini.config_reader import get_gemini_config_paths, load_gemini_configs
```

**âœ… æ–°å†™æ³•ï¼ˆé€‰é¡¹ Aï¼‰**ï¼š
```python
from dags.gemini.config_reader import (
    get_config_path,
    load_json_config,
    load_markdown_template
)
```

### 2. è°ƒåº¦ä½¿ç”¨ Airflow Variableï¼Œè€Œéç¡¬ç¼–ç ï¼ˆå·²ä¿®æ­£ï¼‰
**âŒ æ—§å†™æ³•**ï¼š
```python
schedule_interval='0 22 * * *',  # 06:00 BJT
```

**âœ… æ–°å†™æ³•**ï¼š
```python
schedule_interval=Variable.get("gemini_dag_schedule", default_var="0 22 * * *"),  # ä» Airflow Variable è¯»å–
```

### 3. æ—¥ç•Œå£å¾„è¦æ˜¾å¼ä¼ å…¥ï¼ˆå·²ä¿®æ­£ï¼‰
**âœ… æ­£ç¡®å®ç°**ï¼š
```python
def find_input_file(**context):
    """æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶"""
    # è·å–å¯é…ç½®çš„æ—¥ç•Œ
    try:
        from airflow.models import Variable
        cutoff_hour = get_cutoff_hour(lambda k: Variable.get(k, default_var=None))
    except Exception:
        cutoff_hour = get_cutoff_hour()
    
    # ä½¿ç”¨ time_utils è®¡ç®—é€»è¾‘æ—¥æœŸï¼ˆæ”¯æŒå¯é…ç½®æ—¥ç•Œï¼‰
    run_dt_utc = context['execution_date']
    logical_date = prev_logical_date_str(run_dt_utc, cutoff_hour=cutoff_hour)
    
    # æŸ¥æ‰¾ Phoenix æ‘˜è¦æ–‡ä»¶
    phoenix_exports_dir = get_config_path("phoenix_exports_dir", "/opt/airflow/exports")
    # æ”¯æŒå›é€€æœºåˆ¶
    pass
```

### 4. å¯¼å…¥éƒ¨åˆ†å®Œæ•´ä¿®æ­£
```python
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from dags.phoenix.time_utils import get_cutoff_hour, prev_logical_date_str
from dags.gemini.config_reader import (
    get_config_path,
    load_json_config,
    load_markdown_template
)
from dags.gemini.validators import validate_cards
from dags.gemini.renderers import render_markdown
```

## å¾®è°ƒè¦ç‚¹æ€»ç»“

1. **å¯¼å…¥ä¿®æ­£**ï¼šä»…ä½¿ç”¨ç°æœ‰çš„ä¸‰ä¸ªå‡½æ•°ï¼Œä¸æ–°å¢ä»»ä½•å‡½æ•°
2. **è°ƒåº¦é…ç½®**ï¼šä½¿ç”¨ Airflow Variable è¯»å–ï¼Œæ”¯æŒæ— ä»£ç æ”¹åŠ¨å³å¯è°ƒåº¦å˜æ›´
3. **æ—¥ç•Œå£å¾„**ï¼šæ˜¾å¼ä¼ å…¥ cutoff_hour å‚æ•°ï¼Œç¡®ä¿æ‰€æœ‰ç­›é€‰å’Œæ–‡ä»¶åŒ¹é…éƒ½ä»¥"åŒ—äº¬æ—¶é—´ 6AM æ—¥ç•Œ"å£å¾„ä¸ºå‡†ï¼ˆä¸”å¯é…ç½®ï¼‰
4. **å¤ç”¨èƒ½åŠ›**ï¼šå……åˆ†åˆ©ç”¨ Milestone 1 çš„ time_utils å’Œ Milestone 2 çš„ config_reader èƒ½åŠ›

## æœ€ç»ˆç¡®è®¤

ä»¥ä¸Šå¾®è°ƒå·²å…¨éƒ¨å®Œæˆï¼Œç¡®ä¿ï¼š
- âœ… å¯¼å…¥æ–¹å¼æ­£ç¡®ï¼ˆä»…ä½¿ç”¨ç°æœ‰çš„ä¸‰ä¸ªå‡½æ•°ï¼‰
- âœ… è°ƒåº¦é…ç½®ä½¿ç”¨ Airflow Variable
- âœ… æ—¥ç•Œå£å¾„å¯é…ç½®ï¼Œå¤ç”¨ Milestone 1 èƒ½åŠ›
- âœ… æ‰€æœ‰ç­›é€‰å’Œæ–‡ä»¶åŒ¹é…éƒ½ä»¥"åŒ—äº¬æ—¶é—´ 6AM æ—¥ç•Œ"å£å¾„ä¸ºå‡†

è¯·ç¡®è®¤æ˜¯å¦å¯ä»¥å¼€å§‹å®æ–½ï¼Ÿ

# ====================== Milestone 3 ä¿®å¤è¡¥ä¸æ–¹æ¡ˆ ======================

## æˆ‘å¯¹æœ¬ä»»åŠ¡çš„ç†è§£ä¸æ‰§è¡Œæ–¹æ¡ˆè¯¦ç»†é˜è¿°

### ğŸ¯ ä»»åŠ¡ç›®æ ‡
ä¸º Milestone 3 çš„ Gemini DAG æ·»åŠ çœŸå®çš„ Gemini API è°ƒç”¨èƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š
1. æ–°å¢ Airflow Variables é…ç½®
2. å®ç° `call_gemini_json` æ ¸å¿ƒå‡½æ•°
3. åœ¨ `select_top10` å’Œ `write_cards` ä¸­æ·»åŠ  dry-run ä¸ live æ¨¡å¼åˆ‡æ¢
4. å®Œå–„ validators ä¸­çš„ hashtag å¤„ç†
5. ç»Ÿä¸€è¾“å‡ºç›®å½•åˆ›å»ºé€»è¾‘

### ğŸ“‹ å…·ä½“å®æ–½è®¡åˆ’

#### 1. æ–°å¢ Airflow Variables è¯»å–
åœ¨ DAG ä¸­æ·»åŠ ä»¥ä¸‹ Variables çš„è¯»å–ï¼š
- `gemini_model_id` (é»˜è®¤: "gemini-2.5-pro")
- `gemini_project_id` (å¿…éœ€ï¼Œç”¨äº Vertex AI åˆå§‹åŒ–)
- `gemini_location` (é»˜è®¤: "us-central1")
- `gemini_dry_run` (é»˜è®¤: "true"ï¼Œæ§åˆ¶æ˜¯å¦çœŸå®è°ƒç”¨ API)

#### 2. å®ç° `call_gemini_json` æ ¸å¿ƒå‡½æ•°
```python
def call_gemini_json(model_id: str, system_text: str, user_payload: str, expect_schema: dict) -> dict:
    """
    è°ƒç”¨ Gemini API å¹¶è¿”å› JSON å“åº”
    
    Args:
        model_id: Gemini æ¨¡å‹ ID
        system_text: ç³»ç»ŸæŒ‡ä»¤
        user_payload: ç”¨æˆ·è¾“å…¥
        expect_schema: æœŸæœ›çš„ JSON Schema
        
    Returns:
        dict: è§£æåçš„ JSON å“åº”
    """
    # åˆå§‹åŒ– Vertex AI
    # æ„é€  GenerativeModel
    # è°ƒç”¨ generate_content
    # è§£æ JSON å“åº”
    # å¼‚å¸¸å¤„ç†å’Œé‡è¯•é€»è¾‘
    # è®°å½• metrics
```

#### 3. ä¿®æ”¹ `select_top10` å’Œ `write_cards` ä»»åŠ¡
æ·»åŠ  dry-run ä¸ live æ¨¡å¼åˆ‡æ¢ï¼š
```python
# è¯»å– dry_run é…ç½®
dry_run = Variable.get("gemini_dry_run", default_var="true").lower() == "true"

if dry_run:
    # æ¨¡æ‹Ÿè¿”å›ç»“æœ
    logger.info("ğŸ¤– Dry-run æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿç»“æœ")
    # è¿”å›æ¨¡æ‹Ÿçš„ Top10 æˆ–å¡ç‰‡æ•°æ®
else:
    # çœŸå®è°ƒç”¨ Gemini API
    logger.info("ğŸš€ Live æ¨¡å¼ï¼šè°ƒç”¨çœŸå® Gemini API")
    result = call_gemini_json(model_id, system_text, user_payload, expect_schema)
```

#### 4. å®Œå–„ validators.py
ç¡®ä¿ `validate_hashtags` å’Œ `fix_hashtags` å‡½æ•°å®Œæ•´å®ç°ï¼š
- `validate_hashtags`: æ£€æŸ¥ hashtag æ ¼å¼å’Œæ•°é‡
- `fix_hashtags`: ä¿®å¤ hashtag æ ¼å¼é—®é¢˜

#### 5. ç»Ÿä¸€è¾“å‡ºç›®å½•åˆ›å»º
åœ¨æ‰€æœ‰éœ€è¦å†™å…¥æ–‡ä»¶çš„åœ°æ–¹æ·»åŠ ï¼š
```python
os.makedirs(gemini_outputs_dir, exist_ok=True)
```

#### 6. ä¿®æ”¹ logical_date è·å–æ–¹å¼
ä» `context["logical_date"]` è·å–ï¼Œè€Œä¸æ˜¯ä» xcom_pull

### ğŸ”§ å…³é”®å®ç°ç»†èŠ‚

#### Gemini API è°ƒç”¨æµç¨‹
1. **åˆå§‹åŒ–**: `vertexai.init(project=project_id, location=location)`
2. **æ¨¡å‹åˆ›å»º**: `GenerativeModel(model_id)`
3. **å†…å®¹ç”Ÿæˆ**: `model.generate_content([system_text, user_payload], generation_config={...})`
4. **å“åº”è§£æ**: `json.loads(response.text)`
5. **å¼‚å¸¸å¤„ç†**: é‡è¯•æœºåˆ¶å’Œé”™è¯¯è®°å½•

#### é‡è¯•å’Œ Metrics è®°å½•
- æœ€å¤§é‡è¯•æ¬¡æ•°: 3
- è®°å½•é‡è¯•æ¬¡æ•°ã€å“åº”é•¿åº¦ã€è§£æçŠ¶æ€
- ä¿å­˜åˆ° metrics JSON æ–‡ä»¶

#### Dry-run æ¨¡å¼
- é»˜è®¤å¯ç”¨ï¼Œç¡®ä¿å¼€å‘æµ‹è¯•å®‰å…¨
- è¿”å›ç»“æ„åŒ–çš„æ¨¡æ‹Ÿæ•°æ®
- ä¿æŒä¸çœŸå® API ç›¸åŒçš„æ•°æ®æ ¼å¼

### ğŸ“ å˜æ›´æ–‡ä»¶åˆ—è¡¨

1. **`dags/gemini/gemini_card_generation_dag.py`**
   - æ·»åŠ æ–°çš„ Airflow Variables è¯»å–
   - å®ç° `call_gemini_json` å‡½æ•°
   - ä¿®æ”¹ `select_top10` å’Œ `write_cards` ä»»åŠ¡
   - ç»Ÿä¸€è¾“å‡ºç›®å½•åˆ›å»ºé€»è¾‘

2. **`dags/gemini/validators.py`**
   - å®Œå–„ `validate_hashtags` å’Œ `fix_hashtags` å‡½æ•°

### ğŸ§ª éªŒæ”¶æ ‡å‡†

1. **éªŒè¯è„šæœ¬é€šè¿‡**: `python dev/verify_milestone3.py` å…¨éƒ¨ âœ…
2. **Dry-run æ¨¡å¼**: èƒ½æ­£å¸¸ç”Ÿæˆ md/metrics æ–‡ä»¶
3. **Live æ¨¡å¼**: é…ç½®çœŸå®å‡­æ®åèƒ½æˆåŠŸè°ƒç”¨ Gemini API
4. **Metrics å®Œæ•´**: åŒ…å«é‡è¯•æ¬¡æ•°ã€å“åº”é•¿åº¦ã€è§£æçŠ¶æ€ç­‰

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **å‡­æ®å®‰å…¨**: ç¡®ä¿æœåŠ¡è´¦å·å‡­æ®æ­£ç¡®é…ç½®
2. **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
3. **æ—¥å¿—è®°å½•**: è¯¦ç»†çš„è°ƒè¯•å’Œé”™è¯¯æ—¥å¿—
4. **å‘åå…¼å®¹**: ä¿æŒ dry-run æ¨¡å¼ä½œä¸ºé»˜è®¤ï¼Œç¡®ä¿å®‰å…¨

## å…³é”®ä»£ç æ®µé¢„è§ˆ

### 1. è¯»å–æ–°å¢ Variables çš„ä»£ç 
```python
# åœ¨ DAG é¡¶éƒ¨æ·»åŠ 
gemini_model_id = Variable.get("gemini_model_id", default_var="gemini-2.5-pro")
gemini_project_id = Variable.get("gemini_project_id", default_var="")
gemini_location = Variable.get("gemini_location", default_var="us-central1")
gemini_dry_run = Variable.get("gemini_dry_run", default_var="true").lower() == "true"
```

### 2. call_gemini_json çš„æ ¸å¿ƒå®ç°
```python
def call_gemini_json(model_id: str, system_text: str, user_payload: str, expect_schema: dict) -> dict:
    """è°ƒç”¨ Gemini API å¹¶è¿”å› JSON å“åº”"""
    import vertexai
    from vertexai.generative_models import GenerativeModel
    
    # åˆå§‹åŒ– Vertex AI
    vertexai.init(project=gemini_project_id, location=gemini_location)
    
    # æ„é€ æ¨¡å‹
    model = GenerativeModel(model_id)
    
    # è°ƒç”¨ API
    response = model.generate_content(
        [system_text, user_payload],
        generation_config={
            "temperature": 0.5,
            "max_output_tokens": 2048,
            "response_mime_type": "application/json"
        }
    )
    
    # è§£æå“åº”
    return json.loads(response.text)
```

### 3. select_top10 / write_cards ä¸­ dry-run ä¸ live è·¯å¾„åˆ‡æ¢ç‰‡æ®µ
```python
def select_top10(**context):
    """é€‰æ‹© Top10 æ–‡ç« """
    # è·å–é…ç½®
    dry_run = Variable.get("gemini_dry_run", default_var="true").lower() == "true"
    
    if dry_run:
        logger.info("ğŸ¤– Dry-run æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿ Top10 ç»“æœ")
        # è¿”å›æ¨¡æ‹Ÿç»“æœ
        top10_indices = [{'index': i, 'reason': f'æ¨¡æ‹Ÿé€‰æ‹©ç¬¬{i+1}ç¯‡'} for i in range(10)]
    else:
        logger.info("ğŸš€ Live æ¨¡å¼ï¼šè°ƒç”¨çœŸå® Gemini API")
        # çœŸå® API è°ƒç”¨
        result = call_gemini_json(model_id, system_text, user_payload, expect_schema)
        top10_indices = result.get('top10', [])
    
    return top10_indices
```

### 4. validators.py ä¸­ validate_hashtags / fix_hashtags çš„å…³é”®é€»è¾‘
```python
def validate_hashtags(hashtags: List[str]) -> bool:
    """éªŒè¯ hashtag æ ¼å¼æ˜¯å¦æ­£ç¡®"""
    if not isinstance(hashtags, list):
        return False
    
    if len(hashtags) < 2 or len(hashtags) > 5:
        return False
    
    for tag in hashtags:
        if not isinstance(tag, str) or not tag.startswith("#"):
            return False
    
    return True

def fix_hashtags(hashtags: List[str]) -> List[str]:
    """ä¿®å¤ hashtag æ ¼å¼"""
    if not isinstance(hashtags, list):
        return ["#æ–°é—»", "#æ—¶æ”¿"]
    
    fixed_hashtags = []
    for tag in hashtags:
        if isinstance(tag, str):
            if not tag.startswith("#"):
                tag = "#" + tag
            fixed_hashtags.append(tag)
    
    # ç¡®ä¿æ•°é‡åœ¨ 2-5 ä¹‹é—´
    if len(fixed_hashtags) < 2:
        fixed_hashtags.extend(["#æ–°é—»", "#æ—¶æ”¿"])
    elif len(fixed_hashtags) > 5:
        fixed_hashtags = fixed_hashtags[:5]
    
    return fixed_hashtags
```

## å¾…ç¡®è®¤åå¼€å§‹å®æ–½

ä»¥ä¸Šæ˜¯ Milestone 3 ä¿®å¤è¡¥ä¸çš„è¯¦ç»†æ‰§è¡Œæ–¹æ¡ˆï¼Œå·²å®Œæ•´è®°å½•åˆ° notes æ–‡ä»¶ä¸­ã€‚è¯·ç¡®è®¤ï¼š

1. **æ–°å¢ Variables è¯»å–**æ˜¯å¦æ­£ç¡®ï¼Ÿ
2. **call_gemini_json å®ç°**æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Ÿ
3. **dry-run ä¸ live æ¨¡å¼åˆ‡æ¢**æ˜¯å¦åˆç†ï¼Ÿ
4. **validators å®Œå–„**æ˜¯å¦å……åˆ†ï¼Ÿ
5. **éªŒæ”¶æ ‡å‡†**æ˜¯å¦æ˜ç¡®ï¼Ÿ

ç¡®è®¤æ— è¯¯åï¼Œæˆ‘å°†ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šæ–¹æ¡ˆå¼€å§‹å®æ–½ï¼Œç¡®ä¿ï¼š
- ä¸¥æ ¼æ‰§è¡Œå·²ç¡®å®šçš„æ–¹æ¡ˆ
- å¦‚é‡é—®é¢˜ä¸ç»•å¼€ï¼Œå…ˆä¸æ‚¨ç¡®è®¤
- ç¡®ä¿ç°æœ‰åŠŸèƒ½ä¸å—å½±å“
- æ‰€æœ‰åŠŸèƒ½æŒ‰è®¾è®¡å®ç°

è¯·ç¡®è®¤æ˜¯å¦å¯ä»¥å¼€å§‹å®æ–½ï¼Ÿ

# ====================== Milestone 3 åŠ å›ºè¡¥ä¸æ–¹æ¡ˆ ======================

## æˆ‘å¯¹æœ¬ä»»åŠ¡çš„ç†è§£ä¸æ‰§è¡Œæ–¹æ¡ˆè¯¦ç»†é˜è¿°

### ğŸ¯ ä»»åŠ¡ç›®æ ‡
ä¸º Milestone 3 æ·»åŠ åŠ å›ºè¡¥ä¸ï¼Œå®ç°ï¼š
1. **é»˜è®¤ä¸å›é€€**ï¼šGemini å®æ—¶è°ƒç”¨å¤±è´¥ â†’ ä»»åŠ¡ç›´æ¥å¤±è´¥ï¼ˆAirflow æ ‡çº¢ï¼‰
2. **æœ¬åœ° Schema æ ¡éªŒ**ï¼šGemini è¿”å›æˆåŠŸä¹Ÿè¦è¿‡ `jsonschema.validate()`ï¼Œä¸åˆè§„å°±å½“å¤±è´¥å¤„ç†
3. **å¯é€‰å›é€€æœºåˆ¶**ï¼šé€šè¿‡ `gemini_allow_fallback_on_failure` å¼€å…³æ§åˆ¶æ˜¯å¦å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®

### ğŸ“‹ å…·ä½“å®æ–½è®¡åˆ’

#### 1. æ–°å¢ Airflow Variable
- `gemini_allow_fallback_on_failure` (é»˜è®¤: "false"ï¼Œä¸å›é€€)

#### 2. ä¾èµ–ç®¡ç†
- åœ¨ `requirements.txt` å¢åŠ ï¼š`jsonschema>=4.22`

#### 3. ä»£ç çº§æ”¹åŠ¨

##### 3.1 è¯»å–æ–°å¼€å…³
```python
allow_fallback = Variable.get("gemini_allow_fallback_on_failure", default_var="false").lower() == "true"
```

##### 3.2 åŠ å›º call_gemini_json å‡½æ•°
- å¤±è´¥å³æŠ›ï¼Œä¸åšé™é»˜å›é€€
- æ·»åŠ  `jsonschema.validate()` æ ¡éªŒ
- é‡è¯•æœºåˆ¶ä¿æŒä¸å˜

##### 3.3 ä¿®æ”¹ select_top10 / write_cards
- åŸæœ‰çš„ dry-run è·¯å¾„ä¸åŠ¨
- åªæœ‰åœ¨ `dry_run == False` ä¸” Live å¤±è´¥æ—¶ï¼Œæ‰çœ‹ `allow_fallback`
- æ˜¾å¼æ ‡è®° fallback ä½¿ç”¨æƒ…å†µ

##### 3.4 å¢å¼º save_metrics
- æ·»åŠ  `fallback_used`ã€`last_error`ã€`schema_validated` ç­‰å¯è§‚æµ‹å­—æ®µ

### ğŸ”§ å…³é”®å®ç°ç»†èŠ‚

#### è¡Œä¸ºå¯¹æ¯”
| åœºæ™¯ | æ—§è¡Œä¸ºï¼ˆå½“å‰ï¼‰ | æ–°è¡Œä¸ºï¼ˆé»˜è®¤ï¼‰ | æ–°è¡Œä¸ºï¼ˆæ‰“å¼€ allow_fallbackï¼‰ |
|------|----------------|----------------|-------------------------------|
| Live æˆåŠŸ + è¿”å›åˆè§„ | æˆåŠŸ | æˆåŠŸ | æˆåŠŸ |
| Live æˆåŠŸ + è¿”å›ä¸åˆè§„ | å¯èƒ½ä»¥"çœ‹ä¼¼æˆåŠŸä½†æ•°æ®æœ‰å‘"è½ç›˜ | å¤±è´¥ï¼ˆæ ‡çº¢ï¼‰ | å›é€€åˆ°æ¨¡æ‹Ÿï¼ˆå¹¶åœ¨ metrics æ ‡è®° fallbackï¼‰ |
| Live å¤±è´¥ï¼ˆç½‘ç»œ/é‰´æƒç­‰ï¼‰ | é™é»˜å›é€€æ¨¡æ‹Ÿæ•°æ® | å¤±è´¥ï¼ˆæ ‡çº¢ï¼‰ | å›é€€åˆ°æ¨¡æ‹Ÿï¼ˆå¹¶åœ¨ metrics æ ‡è®° fallbackï¼‰ |
| Dry-run=true | ä¸€ç›´æ¨¡æ‹Ÿ | ä¸€ç›´æ¨¡æ‹Ÿ | ä¸€ç›´æ¨¡æ‹Ÿ |

#### é£é™©ä¸å›æ»š
- **é£é™©**ï¼šé»˜è®¤æ”¹ä¸º"å¤±è´¥ä¸å›é€€"ï¼Œç¬¬ä¸€æ¬¡ä¸Šçº¿è‹¥ Vertex å‡­æ®/é…é¢æœ‰é—®é¢˜ï¼ŒDAG ä¼šæ ‡çº¢
- **å›æ»š**ï¼šç›´æ¥æŠŠ `gemini_allow_fallback_on_failure=true`ï¼Œæ— éœ€æ”¹ä»£ç å³å¯æ¢å¤æ—§è¡Œä¸º

### ğŸ§ª éªŒæ”¶æ ‡å‡†

1. **é»˜è®¤ä¸å¼€å›é€€**ï¼šè®¾ç½® `gemini_dry_run=false`ã€`gemini_allow_fallback_on_failure=false`ã€æ•…æ„è®© Live å¤±è´¥ï¼ŒæœŸæœ›ä»»åŠ¡å¤±è´¥ï¼ŒDAG æ ‡çº¢
2. **æ‰“å¼€å›é€€**ï¼šè®¾ç½® `gemini_dry_run=false`ã€`gemini_allow_fallback_on_failure=true`ã€ä»è®© Live å¤±è´¥ï¼ŒæœŸæœ› DAG æˆåŠŸï¼Œmetrics æ ‡è®° fallback
3. **Schema æ ¡éªŒç”Ÿæ•ˆ**ï¼šè®¾ç½® `gemini_dry_run=false`ã€`allow_fallback=false`ï¼Œmock ç»“æ„ä¸åˆè§„çš„å“åº”ï¼ŒæœŸæœ› jsonschema_validate æŠ›é”™ â†’ ä»»åŠ¡å¤±è´¥

## å…³é”®ä»£ç æ®µé¢„è§ˆ

### 1. è¯»å–æ–°å¼€å…³
```python
# è¯»å–æ–°å¼€å…³
allow_fallback = Variable.get("gemini_allow_fallback_on_failure", default_var="false").lower() == "true"
```

### 2. åŠ å›º call_gemini_json å‡½æ•°
```python
def call_gemini_json(model_id: str, system_text: str, user_payload: str, expect_schema: dict, max_retries: int = 3) -> dict:
    import vertexai
    from vertexai.generative_models import GenerativeModel
    from jsonschema import validate as jsonschema_validate, ValidationError
    import json, time, logging
    logger = logging.getLogger(__name__)

    vertexai.init(project=gemini_project_id, location=gemini_location)
    model = GenerativeModel(model_id)

    last_err = None
    for attempt in range(1, max_retries + 1):
        try:
            resp = model.generate_content(
                [system_text, user_payload],
                generation_config={
                    "temperature": 0.5,
                    "max_output_tokens": 2048,
                    "response_mime_type": "application/json"
                }
            )
            data = json.loads(resp.text)

            # æœ¬åœ° Schema æ ¡éªŒï¼ˆæ–°å¢çš„å¼ºæ ¡éªŒï¼‰
            jsonschema_validate(instance=data, schema=expect_schema)
            return data
        except (Exception, ValidationError) as e:
            last_err = e
            logger.warning("Gemini call/schema validate failed (attempt %s/%s): %s", attempt, max_retries, e)
            if attempt < max_retries:
                time.sleep(2 * attempt)
    # å…¨éƒ¨å¤±è´¥åæŠ›å‡ºï¼Œè®©ä¸Šå±‚æŒ‰ allow_fallback å†³ç­–
    raise RuntimeError(f"Gemini call failed after {max_retries} attempts: {last_err}")
```

### 3. select_top10 / write_cards æ–°çš„å¼‚å¸¸åˆ†æ”¯
```python
def select_top10(**context):
    # ...å‡†å¤‡ system_instruction, select_top_schema, user_payload ç­‰
    try:
        if gemini_dry_run:
            context['ti'].xcom_push(key="fallback_used", value=False)
            # è¿”å›æ¨¡æ‹Ÿ top10
            return [{'index': i, 'reason': f'æ¨¡æ‹Ÿé€‰æ‹©ç¬¬{i+1}ç¯‡'} for i in range(10)]
        else:
            res = call_gemini_json(gemini_model_id, system_instruction, user_payload, select_top_schema)
            context['ti'].xcom_push(key="fallback_used", value=False)
            return res.get('top10', [])
    except Exception as e:
        context['ti'].xcom_push(key="last_error", value=str(e))
        if allow_fallback:
            # æœ‰æ„å›é€€ï¼šç”Ÿæˆæ¨¡æ‹Ÿ top10ï¼Œå¹¶**æ˜¾å¼æ ‡è®°** fallback
            context['ti'].xcom_push(key="fallback_used", value=True)
            return [{'index': i, 'reason': f'Fallback ç¬¬{i+1}ç¯‡'} for i in range(10)]
        # é»˜è®¤ï¼šä¸å›é€€ï¼Œä»»åŠ¡å¤±è´¥
        raise
```

### 4. metrics å­—æ®µå¢å¼º
```python
def save_metrics(**context):
    ti = context['ti']
    metrics = {
        # ...ä½ å·²æœ‰çš„ç»Ÿè®¡
        "dry_run": gemini_dry_run,
        "fallback_used": bool(ti.xcom_pull(key="fallback_used")),
        "last_error": ti.xcom_pull(key="last_error") or "",
        # å½“ä¸”ä»…å½“ live + æˆåŠŸ + è¿‡ schema æ ¡éªŒæ—¶ï¼Œç”± call_gemini_json è°ƒç”¨æˆåŠŸæ¥ä»£è¡¨
        "schema_validated": (not gemini_dry_run) and (not bool(ti.xcom_pull(key="fallback_used"))) and (ti.xcom_pull(key="last_error") is None),
    }
    # ...è½ç›˜é€»è¾‘ä¸å˜
```

### 5. requirements.txt å˜æ›´
```
jsonschema>=4.22
```

## å¾…ç¡®è®¤åå¼€å§‹å®æ–½

ä»¥ä¸Šæ˜¯ Milestone 3 åŠ å›ºè¡¥ä¸çš„è¯¦ç»†æ‰§è¡Œæ–¹æ¡ˆï¼Œå·²å®Œæ•´è®°å½•åˆ° notes æ–‡ä»¶ä¸­ã€‚è¯·ç¡®è®¤ï¼š

1. **é»˜è®¤ä¸å›é€€æœºåˆ¶**æ˜¯å¦æ­£ç¡®ï¼Ÿ
2. **Schema æ ¡éªŒå®ç°**æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Ÿ
3. **å¯é€‰å›é€€å¼€å…³**æ˜¯å¦åˆç†ï¼Ÿ
4. **Metrics å­—æ®µå¢å¼º**æ˜¯å¦å……åˆ†ï¼Ÿ
5. **éªŒæ”¶æ ‡å‡†**æ˜¯å¦æ˜ç¡®ï¼Ÿ

ç¡®è®¤æ— è¯¯åï¼Œæˆ‘å°†ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šæ–¹æ¡ˆå¼€å§‹å®æ–½ï¼Œç¡®ä¿ï¼š
- ä¸¥æ ¼æ‰§è¡Œå·²ç¡®å®šçš„æ–¹æ¡ˆ
- å¦‚é‡é—®é¢˜ä¸ç»•å¼€ï¼Œå…ˆä¸æ‚¨ç¡®è®¤
- ç¡®ä¿ç°æœ‰åŠŸèƒ½ä¸å—å½±å“
- æ‰€æœ‰åŠŸèƒ½æŒ‰è®¾è®¡å®ç°

è¯·ç¡®è®¤æ˜¯å¦å¯ä»¥å¼€å§‹å®æ–½ï¼Ÿ

# ====================== Milestone 3: Gemini ç®€æŠ¥ç”Ÿæˆ DAG ======================

## ä»»åŠ¡ç†è§£ä¸æ‰§è¡Œæ–¹æ¡ˆè¯¦ç»†é˜è¿°

### 1. ä»»åŠ¡ç›®æ ‡
å®ç° `gemini_card_generation_dag`ï¼Œå®Œæˆä» Phoenix æ‘˜è¦æ–‡ä»¶åˆ° Gemini API è°ƒç”¨ï¼Œå†åˆ°ç”Ÿæˆé€‰é¢˜å¡ç‰‡ JSON å’Œæ¸²æŸ“ Markdown æŠ¥å‘Šçš„å…¨é“¾è·¯ã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- æ¯æ—¥åŒ—äº¬æ—¶é—´ 06:00 è‡ªåŠ¨è§¦å‘
- è¯»å– Phoenix æ‘˜è¦æ–‡ä»¶
- è°ƒç”¨ Gemini API ç”Ÿæˆé€‰é¢˜å¡ç‰‡
- æ ¡éªŒå’Œä¿®å¤å¡ç‰‡å†…å®¹
- æ¸²æŸ“ Markdown æŠ¥å‘Š
- ä¿å­˜åˆ°æŒ‡å®šè¾“å‡ºç›®å½•

### 2. è®¾è®¡çº¦æŸ
- **DAG ID**: `gemini_card_generation_dag`
- **è°ƒåº¦æ—¶é—´**: 06:00 BJTï¼ˆä½¿ç”¨ Airflow Variable: `gemini_dag_schedule`ï¼‰
- **è¾“å…¥æ–‡ä»¶**: Phoenix exports/ ç›®å½•ï¼ˆä½¿ç”¨ `time_utils.py` è®¡ç®—é€»è¾‘æ—¥æœŸï¼‰
- **è¾“å‡ºæ–‡ä»¶**: gemini_outputs_dirï¼ˆAirflow Variableï¼‰
- **æ–‡ä»¶å‘½å**: `YYYY-MM-DD_HH-MM-SS_daily_briefing.md`
- **Gemini æ¨¡å‹**: `gemini-2.5-pro`

### 3. æ‰§è¡Œæ–¹æ¡ˆé€ç‚¹è¯´æ˜

#### 3.1 DAG æµç¨‹è®¾è®¡
```
find_input â†’ pre_filter â†’ select_top10 â†’ write_cards â†’ validate_and_fix â†’ render_markdown â†’ save_metrics
```

**ä»»åŠ¡é“¾è¯¦ç»†è¯´æ˜**ï¼š

1. **find_input ä»»åŠ¡**
   - è°ƒç”¨ `prev_logical_date_str(run_dt_utc)` è®¡ç®—å‰ä¸€æ—¥é€»è¾‘æ—¥æœŸ
   - åœ¨ `phoenix_exports_dir` ä¸­æŸ¥æ‰¾å¯¹åº”çš„ JSON æ‘˜è¦æ–‡ä»¶
   - æ‰¾ä¸åˆ°åˆ™å›é€€åˆ°æœ€è¿‘ 48 å°æ—¶æœ€æ–°ä¸€ä»½
   - è¿”å›æ–‡ä»¶è·¯å¾„ç»™ä¸‹æ¸¸ä»»åŠ¡

2. **pre_filter ä»»åŠ¡**
   - è¯»å–æ‘˜è¦ JSON æ–‡ä»¶
   - æ—¶é—´çª—è¿‡æ»¤ï¼šä»…ä¿ç•™ 24 å°æ—¶æ–°é—»
   - å†²çªè¯è¿‡æ»¤ï¼šä½¿ç”¨ `normal_conflict.json`ï¼Œçˆ†ç‚¹ä¾‹å¤–ä½¿ç”¨ `bang_words.json`
   - å»é‡ï¼šåŸºäº URL + æ ‡é¢˜ç›¸ä¼¼åº¦
   - æˆªæ–­æ­£æ–‡ï¼šä½¿ç”¨ Airflow Variable `summary_truncate_chars`ï¼ˆæ¨è 800-1200ï¼‰
   - é™åˆ¶å€™é€‰æ¡æ•°ï¼šä½¿ç”¨ Airflow Variable `cards_topk`ï¼ˆæ¨è â‰¤60ï¼‰
   - ä¿å­˜åˆ° `prefiltered_YYYYMMDD.json`

3. **select_top10 ä»»åŠ¡**
   - è°ƒç”¨ Gemini APIï¼Œç»‘å®š `select_top_schema.json`
   - è¾“å…¥ï¼šå€™é€‰ JSON + ç³»ç»ŸæŒ‡ä»¤ï¼ˆ`system_instruction.md`ï¼‰
   - è¾“å‡ºï¼š10 æ¡ç´¢å¼• + ç®€è¦ç†ç”±
   - è¿”å›é€‰ä¸­çš„ Top10 ç´¢å¼•

4. **write_cards ä»»åŠ¡**
   - è°ƒç”¨ Gemini APIï¼Œç»‘å®š `response_schema.json`
   - è¾“å…¥ï¼šTop10 å€™é€‰æ•°æ®
   - è¾“å‡ºï¼šå®Œæ•´å¡ç‰‡ JSONï¼ˆtitleã€subtitleã€hashtagsã€summaryã€dateã€sourceï¼‰
   - `date` å­—æ®µï¼šæœ¬åœ°å›å¡«é€»è¾‘æ—¥ï¼Œä¸è®©æ¨¡å‹ç”Ÿæˆ
   - `source`ï¼šæœ¬åœ°æ‹¼æ¥ä¸º"åª’ä½“å â€“ URL"
   - ä¿å­˜åˆ° `cards_YYYYMMDD.json`

5. **validate_and_fix ä»»åŠ¡**
   - è°ƒç”¨ `validators.validate_cards`
   - æ ¡éªŒè§„åˆ™ï¼š
     - title â‰¤ 8 ä¸­æ–‡å­—ç¬¦
     - subtitle â‰¤ 12 ä¸­æ–‡å­—ç¬¦
     - summary â‰¤ 200 ä¸­æ–‡å­—ç¬¦
     - hashtags 2-5 ä¸ªï¼Œä¸”ä»¥ # å¼€å¤´
   - ä¸ç¬¦åˆè§„åˆ™çš„æ¡ç›®è¿›è¡Œä¿®å¤æˆ–ä¸¢å¼ƒ
   - è¿”å›æ ¡éªŒåçš„å¡ç‰‡åˆ—è¡¨

6. **render_markdown ä»»åŠ¡**
   - è°ƒç”¨ `renderers.render_markdown`
   - ä½¿ç”¨ `md_template.md.j2` æ¸²æŸ“æ¨¡æ¿
   - è¾“å‡º Markdown æ ¼å¼æŠ¥å‘Š
   - æ–‡ä»¶å‘½åï¼š`YYYY-MM-DD_HH-MM-SS_daily_briefing.md`

7. **save_metrics ä»»åŠ¡**
   - ä¿å­˜è¿è¡ŒæŒ‡æ ‡ JSON
   - åŒ…å«ï¼šå€™é€‰æ¡æ•°ã€Top10 æ˜¯å¦é½å…¨ã€é‡è¯•æ¬¡æ•°ã€token ä¼°ç®—
   - æ–‡ä»¶å‘½åï¼š`metrics_YYYYMMDD.json`

#### 3.2 å…³é”®å®ç°ç»†èŠ‚

**Gemini API è°ƒç”¨**ï¼š
```python
from vertexai.generative_models import GenerativeModel, Part

model = GenerativeModel("gemini-2.5-pro")
response = model.generate_content(
    contents=[system_prompt, user_prompt],
    generation_config={
        "temperature": 0.5,
        "max_output_tokens": 2048,
        "response_mime_type": "application/json"
    }
)
```

**æ ¡éªŒé€»è¾‘æ‰©å±•**ï¼š
```python
def validate_cards(cards: list[dict]) -> list[dict]:
    """æ£€æŸ¥é•¿åº¦ã€hashtagsã€é‡å¤äº‹ä»¶ï¼Œä¸ç¬¦åˆæ—¶æŠ›å¼‚å¸¸æˆ–æ ‡è®°ã€‚"""
    valid = []
    seen_titles = set()
    for c in cards:
        if len(c["title"]) > 8: c["title"] = c["title"][:8]
        if len(c["subtitle"]) > 12: c["subtitle"] = c["subtitle"][:12]
        if len(c["summary"]) > 200: c["summary"] = c["summary"][:200]
        if tuple(c["title"], c["subtitle"]) in seen_titles: continue
        seen_titles.add((c["title"], c["subtitle"]))
        valid.append(c)
    return valid
```

**æ¸²æŸ“é€»è¾‘æ‰©å±•**ï¼š
```python
from jinja2 import Template

def render_markdown(cards: list[dict], template_path: str, logical_date: str) -> str:
    with open(template_path, "r", encoding="utf-8") as f:
        tpl = Template(f.read())
    # summary_points: ç®€å•åˆ‡åˆ† summary å¥å­
    for c in cards:
        sentences = c["summary"].replace("ï¼›","ã€‚").split("ã€‚")
        c["summary_points"] = [s for s in sentences if s][:3]
    return tpl.render(cards=cards, logical_date=logical_date)
```

#### 3.3 æ–‡ä»¶ç»“æ„è®¾è®¡

**æ–°å»ºæ–‡ä»¶**ï¼š
- `dags/gemini/gemini_card_generation_dag.py` - ä¸» DAG æ–‡ä»¶

**ä¿®æ”¹æ–‡ä»¶**ï¼š
- `dags/gemini/validators.py` - æ‰©å±•æ ¡éªŒé€»è¾‘
- `dags/gemini/renderers.py` - æ‰©å±•æ¸²æŸ“é€»è¾‘ï¼Œæ”¯æŒ Jinja2

**è°ƒç”¨å·²æœ‰æ¨¡å—**ï¼š
- `dags/phoenix/time_utils.py` - é€»è¾‘æ—¥æœŸè®¡ç®—
- `dags/gemini/config_reader.py` - é…ç½®è¯»å–

#### 3.4 é…ç½®ç®¡ç†

**æ–°å¢ Airflow Variables**ï¼š
- `gemini_model_id`: "gemini-2.5-pro"
- `summary_truncate_chars`: "1000"
- `cards_topk`: "50"

**ä½¿ç”¨ç°æœ‰ Variables**ï¼š
- `phoenix_exports_dir`: Phoenix æ‘˜è¦æ–‡ä»¶ç›®å½•
- `gemini_outputs_dir`: Gemini è¾“å‡ºç›®å½•
- `gemini_dag_schedule`: DAG è°ƒåº¦æ—¶é—´
- æ‰€æœ‰ prompts/schema/template è·¯å¾„å˜é‡

#### 3.5 é”™è¯¯å¤„ç†ä¸é‡è¯•æœºåˆ¶

**æ–‡ä»¶æŸ¥æ‰¾å¤±è´¥**ï¼š
- å›é€€åˆ°æœ€è¿‘ 48 å°æ—¶æœ€æ–°æ–‡ä»¶
- è®°å½•è­¦å‘Šæ—¥å¿—

**Gemini API è°ƒç”¨å¤±è´¥**ï¼š
- å®ç°é‡è¯•æœºåˆ¶ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
- è®°å½• token ä½¿ç”¨æƒ…å†µ
- å¤±è´¥æ—¶ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ° metrics

**æ ¡éªŒå¤±è´¥**ï¼š
- è‡ªåŠ¨ä¿®å¤å¸¸è§é—®é¢˜
- æ— æ³•ä¿®å¤çš„æ¡ç›®è®°å½•åˆ° metrics
- ç¡®ä¿è‡³å°‘è¿”å› 5 æ¡æœ‰æ•ˆå¡ç‰‡

#### 3.6 è¾“å‡ºæ–‡ä»¶è§„èŒƒ

**æ–‡ä»¶å‘½åè§„åˆ™**ï¼š
- `prefiltered_YYYYMMDD.json` - é¢„è¿‡æ»¤åçš„å€™é€‰æ•°æ®
- `cards_YYYYMMDD.json` - æœ€ç»ˆé€‰é¢˜å¡ç‰‡
- `YYYY-MM-DD_HH-MM-SS_daily_briefing.md` - Markdown æŠ¥å‘Š
- `metrics_YYYYMMDD.json` - è¿è¡ŒæŒ‡æ ‡

**æ–‡ä»¶å†…å®¹è§„èŒƒ**ï¼š
- JSON æ–‡ä»¶ä½¿ç”¨ UTF-8 ç¼–ç 
- Markdown æ–‡ä»¶ä½¿ç”¨ UTF-8 ç¼–ç ï¼Œæ—  BOM
- æ‰€æœ‰æ–‡ä»¶åŒ…å«æ—¶é—´æˆ³å’Œç‰ˆæœ¬ä¿¡æ¯

### 4. éªŒè¯æ ‡å‡†

#### 4.1 åŠŸèƒ½éªŒè¯
- âœ… DAG æ–‡ä»¶å­˜åœ¨ä¸”èƒ½è¢« Airflow åŠ è½½
- âœ… æ¯æ—¥ 06:00 BJT è‡ªåŠ¨è¿è¡Œï¼ˆæˆ–æ‰‹åŠ¨è§¦å‘ï¼‰
- âœ… èƒ½æ­£ç¡®æ‰¾åˆ°å‰ä¸€æ—¥æ‘˜è¦æ–‡ä»¶ï¼ˆæˆ–å›é€€ï¼‰
- âœ… ç”Ÿæˆæ‰€æœ‰å¿…éœ€çš„è¾“å‡ºæ–‡ä»¶

#### 4.2 å†…å®¹éªŒè¯
- âœ… æ ¡éªŒè§„åˆ™ç”Ÿæ•ˆï¼Œè¿è§„æ¡ç›®èƒ½è¢«ä¿®å¤æˆ–ä¸¢å¼ƒ
- âœ… Markdown æŠ¥å‘Šæ ¼å¼ç¬¦åˆæ¨¡æ¿
- âœ… æ ‡é¢˜ â‰¤ 8 å­—ã€å‰¯æ ‡é¢˜ â‰¤ 12 å­—
- âœ… hashtags æ­£ç¡®æ ¼å¼ï¼ˆ2-5 ä¸ªï¼Œå¸¦ #ï¼‰
- âœ… summary åˆ†ä¸‰ç‚¹ç»“æ„

#### 4.3 æ–‡ä»¶éªŒè¯
- âœ… æ–‡ä»¶å‘½åè§„èŒƒ
- âœ… æ–‡ä»¶å†…å®¹æ ¼å¼æ­£ç¡®
- âœ… åŒ…å«å®Œæ•´çš„è¿è¡ŒæŒ‡æ ‡

### 5. æŠ€æœ¯å®ç°è¦ç‚¹

#### 5.1 ä¾èµ–ç®¡ç†
- ä½¿ç”¨ Vertex AI Python SDK
- é›†æˆ Jinja2 æ¨¡æ¿å¼•æ“
- å¤ç”¨ç°æœ‰çš„ time_utils å’Œ config_reader

#### 5.2 æ€§èƒ½ä¼˜åŒ–
- æ‰¹é‡å¤„ç†å€™é€‰æ•°æ®
- ç¼“å­˜é…ç½®æ–‡ä»¶å†…å®¹
- ä¼˜åŒ– Gemini API è°ƒç”¨é¢‘ç‡

#### 5.3 ç›‘æ§ä¸æ—¥å¿—
- è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—
- è¿è¡ŒæŒ‡æ ‡è®°å½•
- é”™è¯¯ä¿¡æ¯è¿½è¸ª

## å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨ä¸å…³é”®ä»£ç æ®µ

### æ–°å»ºæ–‡ä»¶ï¼š
1. `dags/gemini/gemini_card_generation_dag.py` - ä¸» DAG æ–‡ä»¶

### ä¿®æ”¹æ–‡ä»¶ï¼š
1. `dags/gemini/validators.py` - æ‰©å±•æ ¡éªŒé€»è¾‘
2. `dags/gemini/renderers.py` - æ‰©å±•æ¸²æŸ“é€»è¾‘

### å…³é”®ä»£ç æ®µé¢„è§ˆï¼š

#### `dags/gemini/gemini_card_generation_dag.py`
```python
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from dags.phoenix.time_utils import get_cutoff_hour, prev_logical_date_str
from dags.gemini.config_reader import (
    get_config_path,
    load_json_config,
    load_markdown_template
)
from dags.gemini.validators import validate_cards
from dags.gemini.renderers import render_markdown

default_args = {
    'owner': 'phoenix-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'gemini_card_generation_dag',
    default_args=default_args,
    description='Gemini é€‰é¢˜å¡ç‰‡ç”Ÿæˆ DAG',
    schedule_interval=Variable.get("gemini_dag_schedule", default_var="0 22 * * *"),  # ä» Airflow Variable è¯»å–
    catchup=False,
    tags=['gemini', 'news', 'cards']
)

def find_input_file(**context):
    """æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶"""
    # å®ç°é€»è¾‘

def pre_filter_articles(**context):
    """é¢„è¿‡æ»¤æ–‡ç« """
    # å®ç°é€»è¾‘

def select_top10(**context):
    """é€‰æ‹© Top10 æ–‡ç« """
    # å®ç°é€»è¾‘

def write_cards(**context):
    """ç”Ÿæˆé€‰é¢˜å¡ç‰‡"""
    # å®ç°é€»è¾‘

def validate_and_fix(**context):
    """æ ¡éªŒå’Œä¿®å¤å¡ç‰‡"""
    # å®ç°é€»è¾‘

def render_markdown_report(**context):
    """æ¸²æŸ“ Markdown æŠ¥å‘Š"""
    # å®ç°é€»è¾‘

def save_metrics(**context):
    """ä¿å­˜è¿è¡ŒæŒ‡æ ‡"""
    # å®ç°é€»è¾‘

# ä»»åŠ¡å®šä¹‰
find_input_task = PythonOperator(
    task_id='find_input',
    python_callable=find_input_file,
    dag=dag
)

pre_filter_task = PythonOperator(
    task_id='pre_filter',
    python_callable=pre_filter_articles,
    dag=dag
)

select_top10_task = PythonOperator(
    task_id='select_top10',
    python_callable=select_top10,
    dag=dag
)

write_cards_task = PythonOperator(
    task_id='write_cards',
    python_callable=write_cards,
    dag=dag
)

validate_task = PythonOperator(
    task_id='validate_and_fix',
    python_callable=validate_and_fix,
    dag=dag
)

render_task = PythonOperator(
    task_id='render_markdown',
    python_callable=render_markdown_report,
    dag=dag
)

save_metrics_task = PythonOperator(
    task_id='save_metrics',
    python_callable=save_metrics,
    dag=dag
)

# ä»»åŠ¡ä¾èµ–
find_input_task >> pre_filter_task >> select_top10_task >> write_cards_task >> validate_task >> render_task >> save_metrics_task
```

#### `dags/gemini/validators.py` æ‰©å±•
```python
def validate_cards(cards: list[dict]) -> list[dict]:
    """æ£€æŸ¥é•¿åº¦ã€hashtagsã€é‡å¤äº‹ä»¶ï¼Œä¸ç¬¦åˆæ—¶æŠ›å¼‚å¸¸æˆ–æ ‡è®°ã€‚"""
    valid = []
    seen_titles = set()
    
    for c in cards:
        # é•¿åº¦æ ¡éªŒå’Œä¿®å¤
        if len(c["title"]) > 8: 
            c["title"] = c["title"][:8]
        if len(c["subtitle"]) > 12: 
            c["subtitle"] = c["subtitle"][:12]
        if len(c["summary"]) > 200: 
            c["summary"] = c["summary"][:200]
        
        # å»é‡æ£€æŸ¥
        title_key = (c["title"], c["subtitle"])
        if title_key in seen_titles: 
            continue
        seen_titles.add(title_key)
        
        # hashtags æ ¡éªŒ
        if not validate_hashtags(c["hashtags"]):
            c["hashtags"] = fix_hashtags(c["hashtags"])
        
        valid.append(c)
    
    return valid
```

#### `dags/gemini/renderers.py` æ‰©å±•
```python
from jinja2 import Template

def render_markdown(cards: list[dict], template_path: str, logical_date: str) -> str:
    """ä½¿ç”¨ Jinja2 æ¸²æŸ“ Markdown æŠ¥å‘Š"""
    with open(template_path, "r", encoding="utf-8") as f:
        tpl = Template(f.read())
    
    # å¤„ç† summary_points
    for c in cards:
        sentences = c["summary"].replace("ï¼›","ã€‚").split("ã€‚")
        c["summary_points"] = [s.strip() for s in sentences if s.strip()][:3]
    
    return tpl.render(
        cards=cards, 
        logical_date=logical_date,
        generation_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
```

## å¾…ç¡®è®¤åå¼€å§‹å®æ–½

ä»¥ä¸Šæ˜¯è¯¦ç»†çš„æ‰§è¡Œæ–¹æ¡ˆï¼Œå·²å®Œæ•´è®°å½•åˆ° notes æ–‡ä»¶ä¸­ã€‚è¯·ç¡®è®¤ï¼š

1. **DAG æµç¨‹è®¾è®¡**æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Ÿ
2. **ä»»åŠ¡é“¾è®¾è®¡**æ˜¯å¦åˆç†ï¼Ÿ
3. **å®ç°ç»†èŠ‚**æ˜¯å¦æœ‰é—æ¼ï¼Ÿ
4. **æ–‡ä»¶ç»“æ„**æ˜¯å¦å®Œæ•´ï¼Ÿ
5. **éªŒè¯æ ‡å‡†**æ˜¯å¦å……åˆ†ï¼Ÿ

ç¡®è®¤æ— è¯¯åï¼Œæˆ‘å°†ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ–¹æ¡ˆå¼€å§‹å®æ–½ï¼Œç¡®ä¿ï¼š
- ä¸¥æ ¼æ‰§è¡Œå·²ç¡®å®šçš„æ–¹æ¡ˆ
- å¦‚é‡é—®é¢˜ä¸ç»•å¼€ï¼Œå…ˆä¸æ‚¨ç¡®è®¤
- ç¡®ä¿ç°æœ‰ Phoenix æµç¨‹ä¸å—å½±å“
- æ‰€æœ‰åŠŸèƒ½æŒ‰è®¾è®¡å®ç°

è¯·ç¡®è®¤æ˜¯å¦å¯ä»¥å¼€å§‹å®æ–½ï¼Ÿ

