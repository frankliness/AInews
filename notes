docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS raw_events (
    id            BIGSERIAL PRIMARY KEY,
    source        VARCHAR(32),
    title         TEXT,
    body          TEXT,
    published_at  TIMESTAMPTZ,
    url           TEXT UNIQUE,
    likes         INT,
    retweets      INT,
    collected_at  TIMESTAMPTZ DEFAULT now()
);
SQL
)"

docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS summaries (
    id          BIGSERIAL PRIMARY KEY,
    raw_id      BIGINT UNIQUE
                REFERENCES raw_events(id) ON DELETE CASCADE,
    summary_cn  TEXT          NOT NULL,
    summary_en  TEXT          NOT NULL,
    created_at  TIMESTAMPTZ   DEFAULT now()
);
SQL
)"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT id, source, left(title,50) AS title_snip, published_at
      FROM raw_events
      ORDER BY id DESC
      LIMIT 3;"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT COUNT(*) FROM summaries;"

  docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT raw_id, left(summary_cn,40) AS cn_snip,
              left(summary_en,40) AS en_snip,
              created_at
        FROM summaries
    ORDER BY created_at DESC
       LIMIT 5;"



å¦‚æœä½ æƒ³è®© æ‰€æœ‰ raw_events é‡æ–°è¿›å…¥é˜Ÿåˆ—ï¼Œåªè¦æŠŠæ•´ä¸ª summaries è¡¨æ¸…ç©ºå°±è¡Œï¼š


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "TRUNCATE TABLE summaries RESTART IDENTITY;"


  # æŸ¥çœ‹å·æ˜¯å¦å­˜åœ¨
docker volume ls | grep pgadmin-data

# è¿›å…¥å·ç›®å½•ï¼ˆLinux/macOSï¼‰
docker volume inspect pgadmin-data \
  --format '{{ .Mountpoint }}'

# å¤‡ä»½ pgAdmin é…ç½®ï¼ˆå¯é€‰ï¼‰
docker run --rm -v pgadmin-data:/data alpine \
  tar -czf - -C /data . > pgadmin_backup_$(date +%F).tgz

# X API token
AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4

curl -X GET "https://api.twitter.com/2/users/by?usernames=cnviolations,reuters,bbcworld \
  -H "Authorization: AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4"


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.reuters import ReutersScraper
scraper = ReutersScraper()
raw = scraper.fetch()
items = scraper.parse(raw)
print(f"ğŸ” Reuters fetched {len(items)} items")
for i, it in enumerate(items[:3], 1):
    print(f"\nâ€” Item {i} â€”")
    print(it)
PY


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.twitter_source import TwitterScraper
scraper = TwitterScraper()
tweets = list(scraper.fetch_all())
print(f"ğŸ” Twitter fetched {len(tweets)} tweets")
for i, tw in enumerate(tweets[:3], 1):
    print(f"\nâ€” Tweet {i} â€”")
    print(tw.as_dict())
PY
docker compose exec --user root airflow-webserver bash
echo 'export HTTP_PROXY=http://host.docker.internal:1082'  >> /root/.bashrc
echo 'export HTTPS_PROXY=http://host.docker.internal:1082' >> /root/.bashrc
exit



ç³»ç»Ÿè§’è‰²: ä½ æ˜¯ä¸€åèµ„æ·± Python åç«¯ + æ•°æ®å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ Airflowã€LLM APIã€å‘é‡æ•°æ®åº“ã€æ–‡ä»¶ I/Oã€‚

ç›®æ ‡: ä¸ºä¸­æ–‡æ—¶æ”¿è‡ªåª’ä½“æ„å»ºä¸€æ¡â€œæŠ“-åˆ†-é€‰-å†™â€è‡ªåŠ¨é€‰é¢˜æµæ°´çº¿â€”â€”  
- **ä»…æŠ“å–è¿‡å» 24 å°æ—¶çš„æ–°é—»**  
- **GPT ç”„åˆ« + å»é‡**ï¼šåŒä¸€äº‹ä»¶ä»…å†™ä¸€æ¬¡ï¼Œé™¤éåˆ¤å®šä¸ºâ€œé‡å¤§æ›´æ–°â€  
- **æ¯å¤©è¿è¡Œ 4 æ¬¡**ï¼ˆUTC+8 çš„ 00:00ã€06:00ã€12:00ã€18:00ï¼‰ï¼ŒæŠŠç¬¦åˆè¦æ±‚çš„æ‘˜è¦å†™å…¥æœ¬åœ° Markdownï¼ˆæŒ‰æ—¥æœŸèšåˆï¼‰

LANG=zh  # æ”¹æˆ en å¯åˆ‡æ¢è‹±æ–‡
====================== éœ€æ±‚è¯¦æƒ…ï¼ˆv3ï¼‰ ======================
1. **æ•°æ®é‡‡é›† (æŠ“)**
   - æ–°é—»æºï¼šNewsAPIã€EventRegistryã€Reuters RSSã€X/Twitter æŒ‡å®šè´¦å·ã€å¾®åšçƒ­æœ
   - Airflow DAG `schedule_interval="0 */6 * * *"`ï¼Œæ¯æ¬¡ä»…æ‹‰å– `now()-24h` å†…çš„æ–°æ–‡
   - ç»Ÿä¸€å­—æ®µ `id, title, body, published_at, source, url, lang, social_metrics`
2. **åˆç­› + å»é‡ (åˆ†)**
   - GPT-4o å‡½æ•°è°ƒç”¨ï¼šè¿‡æ»¤éã€Œæ”¿æ²»/å†›äº‹/ç§‘æŠ€/ç»æµ/æ–‡åŒ–ã€ã€>24hã€æ— ç‹¬å®¶ç»†èŠ‚ã€å¯¹ç›®æ ‡ç”¨æˆ·æ— ç”¨ çš„æŠ¥æ–‡  
   - **å†å²å»é‡**  
     1. å¯¹ `title+url` ç”Ÿæˆ SimHash â†’ 80 % ç›¸ä¼¼å³åŒäº‹ä»¶  
     2. è‹¥æ•°æ®åº“å·²æœ‰æ‘˜è¦ï¼Œè°ƒç”¨ GPT è¯¢é—® _â€œæ˜¯å¦é‡å¤§æ›´æ–°ï¼Ÿï¼ˆæ˜¯/å¦ + 20 å­—ç†ç”±ï¼‰â€_  
        - å¦ â†’ ä¸¢å¼ƒ  
        - æ˜¯ â†’ è§†ä¸ºæ–°æ‘˜è¦ï¼Œå†™å…¥å¹¶åœ¨ Markdown å¡ç‰‡æ ‡æ³¨â€œã€æ›´æ–°ã€‘â€
3. **é‡åŒ–æ‰“åˆ† (åˆ¤)**
   - å…¬å¼ `score = 0.4*Hot + 0.4*Sim + 0.2*Fresh`  
   - `Hot` = likes + retweets  
   - `Sim` = ä¸"æ—¶æ”¿è§†é¢‘è´¦å·ä¸»é¢˜å‘é‡"ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆFaissï¼‰  
   - `Fresh` = e^(â€“Î”t/24h)  
   - `score > 0.6` å…¥æ± 
4. **æ‘˜è¦ç”Ÿæˆ (å†™)**
   - GPT-4o Few-shot Promptï¼Œè¾“å‡º **JSON**ï¼š
     ```json
     {
       "hashtags": ["#å›½å®¶", "#è®®é¢˜"],   // 2-5 ä¸ª#
       "title": "â‰¤8 å­—ä¸»æ ‡é¢˜",
       "subtitle": "â‰¤12 å­—å‰¯æ ‡é¢˜",
       "summary": "â‘  äº‹ä»¶â€¦â‘¡ èƒŒæ™¯â€¦â‘¢ çœ‹ç‚¹â€¦", // â‰¤200 å­—
       "date": "YYYY-MM-DD",
       "source": "åª’ä½“ â€“ URL",
       "is_update": false           // GPT åˆ¤æ–­çš„é‡å¤§æ›´æ–°æ ‡è®°
     }
     ```
5. **æœ¬åœ°è½ç›˜ (è¾“å‡º)**
   - è·¯å¾„ `./summaries/YYYY-MM-DD.md`ï¼Œæ¯æ—¥å•æ–‡ä»¶ï¼›è‹¥å·²å­˜åœ¨åˆ™è¿½åŠ   
   - Markdown æ¨¡æ¿ï¼š
     ```markdown
     ## {title}ï½œ{subtitle}{% if is_update %}ã€æ›´æ–°ã€‘{% endif %}
     - **{hashtags}**
     - â‘  â€¦ â‘¡ â€¦ â‘¢ â€¦
     - *æ¥æºï¼š{source}*
     ```
   - ç¼–ç  UTF-8ï¼Œæ—  BOM
6. **è¿è¡Œé¢‘æ¬¡**  
   - Airflow DAG `news_pipeline.py`ï¼š`0 */6 * * *`ï¼ˆåŒ—äº¬æ—¶é—´ 00/06/12/18 ç‚¹è§¦å‘ï¼‰

æŠ€æœ¯æ ˆ
-------
- **Python 3.11** ï¼ˆpoetry ç®¡ç†ä¾èµ–ï¼‰  
- Airflow 2.9  
- HTTP: httpx + tenacity é‡è¯•  
- OpenAI SDK â‰¥1.30ï¼ˆå‡½æ•°è°ƒç”¨ï¼‰  
- å‘é‡åº“: faiss-cpu  
- åˆ¤é‡: simhash + Redis Bloom  
- ORM: SQLModel + SQLiteï¼ˆæœ¬åœ°ï¼Œå¯æ›¿æ¢ Postgresï¼‰  
- å•å…ƒæµ‹è¯•: pytest + GitHub Actions CI  

äº¤ä»˜ç‰©
------
1. **ç›®å½•ç»“æ„**

```
