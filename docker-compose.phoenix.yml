# Phoenix News Pipeline V2 - 精英数据动脉
# 专用的 Docker Compose 配置

version: "3.9"

services:
  # PostgreSQL 数据库
  postgres-phoenix:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      - POSTGRES_USER=phoenix_user
      - POSTGRES_PASSWORD=phoenix_pass
      - POSTGRES_DB=phoenix_db
      - TZ=Asia/Shanghai
      - PGTZ=Asia/Shanghai
    volumes:
      - phoenix_postgres_data:/var/lib/postgresql/data
    ports:
      - "5434:5432"  # 使用不同端口避免冲突
    networks:
      - phoenix_network

  # pgAdmin for Phoenix
  pgadmin-phoenix:
    image: dpage/pgadmin4:8.6
    restart: unless-stopped
    depends_on:
      - postgres-phoenix
    environment:
      - PGADMIN_DEFAULT_EMAIL=phoenix@example.com
      - PGADMIN_DEFAULT_PASSWORD=phoenix123
    ports:
      - "5051:80"  # 使用端口 5051 避免冲突
    volumes:
      - phoenix_pgadmin_data:/var/lib/pgadmin
    networks:
      - phoenix_network

  # Redis 缓存
  redis-phoenix:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "6381:6379"  # 使用不同端口避免冲突
    networks:
      - phoenix_network

  # Phoenix Airflow 初始化
  phoenix-init:
    build:
      context: .
      dockerfile: Dockerfile.phoenix
    restart: "no"
    depends_on:
      - postgres-phoenix
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://phoenix_user:phoenix_pass@postgres-phoenix:5432/phoenix_db
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CELERY__BROKER_URL=redis://redis-phoenix:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://phoenix_user:phoenix_pass@postgres-phoenix:5432/phoenix_db
      - EVENTREGISTRY_APIKEY=${EVENTREGISTRY_APIKEY}
      - PYTHONPATH=/opt/airflow:/opt/airflow/dags/phoenix
    command:
      - bash
      - -c
      - |
        airflow db migrate
        airflow users create \
          --username "phoenix_admin" \
          --firstname "Phoenix" \
          --lastname "Admin" \
          --role "Admin" \
          --email "phoenix@example.com" \
          --password "phoenix123"
    networks:
      - phoenix_network

  # Phoenix Airflow Web 服务器
  phoenix-webserver:
    build:
      context: .
      dockerfile: Dockerfile.phoenix
    restart: unless-stopped
    depends_on:
      - phoenix-init
      - postgres-phoenix
      - redis-phoenix
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://phoenix_user:phoenix_pass@postgres-phoenix:5432/phoenix_db
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CELERY__BROKER_URL=redis://redis-phoenix:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://phoenix_user:phoenix_pass@postgres-phoenix:5432/phoenix_db
      - EVENTREGISTRY_APIKEY=${EVENTREGISTRY_APIKEY}
      - PYTHONPATH=/opt/airflow:/opt/airflow/dags/phoenix
    ports:
      - "8082:8080"  # 使用端口 8082 避免冲突
    volumes:
      - ./dags/phoenix:/opt/airflow/dags/phoenix
      - ./config:/opt/airflow/config
      - ./scraper:/opt/airflow/scraper
      - ./sql:/opt/airflow/sql
      - ./utils:/opt/airflow/utils
      - ./logs:/opt/airflow/logs
      - phoenix_logs:/opt/airflow/logs
      - ./exports:/opt/airflow/exports
    networks:
      - phoenix_network

  # Phoenix Airflow 调度器
  phoenix-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.phoenix
    restart: unless-stopped
    depends_on:
      - phoenix-init
      - postgres-phoenix
      - redis-phoenix
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://phoenix_user:phoenix_pass@postgres-phoenix:5432/phoenix_db
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CELERY__BROKER_URL=redis://redis-phoenix:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://phoenix_user:phoenix_pass@postgres-phoenix:5432/phoenix_db
      - EVENTREGISTRY_APIKEY=${EVENTREGISTRY_APIKEY}
      - PYTHONPATH=/opt/airflow:/opt/airflow/dags/phoenix
    volumes:
      - ./dags/phoenix:/opt/airflow/dags/phoenix
      - ./config:/opt/airflow/config
      - ./scraper:/opt/airflow/scraper
      - ./sql:/opt/airflow/sql
      - ./utils:/opt/airflow/utils
      - ./logs:/opt/airflow/logs
      - phoenix_logs:/opt/airflow/logs
      - ./exports:/opt/airflow/exports
    command: ["airflow", "scheduler"]
    networks:
      - phoenix_network

volumes:
  phoenix_postgres_data:
  phoenix_pgadmin_data:
  phoenix_logs:

networks:
  phoenix_network:
    driver: bridge