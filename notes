docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS raw_events (
    id            BIGSERIAL PRIMARY KEY,
    source        VARCHAR(32),
    title         TEXT,
    body          TEXT,
    published_at  TIMESTAMPTZ,
    url           TEXT UNIQUE,
    likes         INT,
    retweets      INT,
    collected_at  TIMESTAMPTZ DEFAULT now()
);
SQL
)"

docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS summaries (
    id          BIGSERIAL PRIMARY KEY,
    raw_id      BIGINT UNIQUE
                REFERENCES raw_events(id) ON DELETE CASCADE,
    summary_cn  TEXT          NOT NULL,
    summary_en  TEXT          NOT NULL,
    created_at  TIMESTAMPTZ   DEFAULT now()
);
SQL
)"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT id, source, left(title,50) AS title_snip, published_at
      FROM raw_events
      ORDER BY id DESC
      LIMIT 3;"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT COUNT(*) FROM summaries;"

  docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT raw_id, left(summary_cn,40) AS cn_snip,
              left(summary_en,40) AS en_snip,
              created_at
        FROM summaries
    ORDER BY created_at DESC
       LIMIT 5;"



如果你想让 所有 raw_events 重新进入队列，只要把整个 summaries 表清空就行：


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "TRUNCATE TABLE summaries RESTART IDENTITY;"


  # 查看卷是否存在
docker volume ls | grep pgadmin-data

# 进入卷目录（Linux/macOS）
docker volume inspect pgadmin-data \
  --format '{{ .Mountpoint }}'

# 备份 pgAdmin 配置（可选）
docker run --rm -v pgadmin-data:/data alpine \
  tar -czf - -C /data . > pgadmin_backup_$(date +%F).tgz

# X API token
AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4

curl -X GET "https://api.twitter.com/2/users/by?usernames=cnviolations,reuters,bbcworld \
  -H "Authorization: AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4"


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.reuters import ReutersScraper
scraper = ReutersScraper()
raw = scraper.fetch()
items = scraper.parse(raw)
print(f"🔎 Reuters fetched {len(items)} items")
for i, it in enumerate(items[:3], 1):
    print(f"\n— Item {i} —")
    print(it)
PY


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.twitter_source import TwitterScraper
scraper = TwitterScraper()
tweets = list(scraper.fetch_all())
print(f"🔎 Twitter fetched {len(tweets)} tweets")
for i, tw in enumerate(tweets[:3], 1):
    print(f"\n— Tweet {i} —")
    print(tw.as_dict())
PY
docker compose exec --user root airflow-webserver bash
echo 'export HTTP_PROXY=http://host.docker.internal:1082'  >> /root/.bashrc
echo 'export HTTPS_PROXY=http://host.docker.internal:1082' >> /root/.bashrc
exit



系统角色: 你是一名资深 Python 后端 + 数据工程师，擅长 Airflow、LLM API、向量数据库、文件 I/O。

目标: 为中文时政自媒体构建一条“抓-分-选-写”自动选题流水线——  
- **仅抓取过去 24 小时的新闻**  
- **GPT 甄别 + 去重**：同一事件仅写一次，除非判定为“重大更新”  
- **每天运行 4 次**（UTC+8 的 00:00、06:00、12:00、18:00），把符合要求的摘要写入本地 Markdown（按日期聚合）

LANG=zh  # 改成 en 可切换英文
====================== 需求详情（v3） ======================
1. **数据采集 (抓)**
   - 新闻源：NewsAPI、EventRegistry、Reuters RSS、X/Twitter 指定账号、微博热搜
   - Airflow DAG `schedule_interval="0 */6 * * *"`，每次仅拉取 `now()-24h` 内的新文
   - 统一字段 `id, title, body, published_at, source, url, lang, social_metrics`
2. **初筛 + 去重 (分)**
   - GPT-4o 函数调用：过滤非「政治/军事/科技/经济/文化」、>24h、无独家细节、对目标用户无用 的报文  
   - **历史去重**  
     1. 对 `title+url` 生成 SimHash → 80 % 相似即同事件  
     2. 若数据库已有摘要，调用 GPT 询问 _“是否重大更新？（是/否 + 20 字理由）”_  
        - 否 → 丢弃  
        - 是 → 视为新摘要，写入并在 Markdown 卡片标注“【更新】”
3. **量化打分 (判)**
   - 公式 `score = 0.4*Hot + 0.4*Sim + 0.2*Fresh`  
   - `Hot` = likes + retweets  
   - `Sim` = 与"时政视频账号主题向量"余弦相似度（Faiss）  
   - `Fresh` = e^(–Δt/24h)  
   - `score > 0.6` 入池
4. **摘要生成 (写)**
   - GPT-4o Few-shot Prompt，输出 **JSON**：
     ```json
     {
       "hashtags": ["#国家", "#议题"],   // 2-5 个#
       "title": "≤8 字主标题",
       "subtitle": "≤12 字副标题",
       "summary": "① 事件…② 背景…③ 看点…", // ≤200 字
       "date": "YYYY-MM-DD",
       "source": "媒体 – URL",
       "is_update": false           // GPT 判断的重大更新标记
     }
     ```
5. **本地落盘 (输出)**
   - 路径 `./summaries/YYYY-MM-DD.md`，每日单文件；若已存在则追加  
   - Markdown 模板：
     ```markdown
     ## {title}｜{subtitle}{% if is_update %}【更新】{% endif %}
     - **{hashtags}**
     - ① … ② … ③ …
     - *来源：{source}*
     ```
   - 编码 UTF-8，无 BOM
6. **运行频次**  
   - Airflow DAG `news_pipeline.py`：`0 */6 * * *`（北京时间 00/06/12/18 点触发）

技术栈
-------
- **Python 3.11** （poetry 管理依赖）  
- Airflow 2.9  
- HTTP: httpx + tenacity 重试  
- OpenAI SDK ≥1.30（函数调用）  
- 向量库: faiss-cpu  
- 判重: simhash + Redis Bloom  
- ORM: SQLModel + SQLite（本地，可替换 Postgres）  
- 单元测试: pytest + GitHub Actions CI  

交付物
------
1. **目录结构**

```
现在您可以通过pgAdmin连接V2数据库：
连接参数：
主机: host.docker.internal
端口: 5434
数据库: ainews
用户名: airflow
密码: airflow_pass

访问 Phoenix Airflow UI: http://localhost:8082
登录凭据:
用户名: phoenix_admin
密码: phoenix123
在 Phoenix UI 中手动触发 DAG:
找到 phoenix_news_pipeline DAG
点击 "Trigger DAG" 按钮

Phoenix 数据库连接参数：
参数	值
Host	localhost
Port	5434
Database	phoenix_db
Username	phoenix_user
Password	phoenix_pass

使用方式
在 Airflow UI 中设置 API Keys：
登录 Airflow UI
导航到 "Admin" -> "Variables"
创建变量 ainews_eventregistry_apikeys，值为 JSON 格式：
{
    "keys": [
        "b03b250a-97ec-4dd0-905e-a038eb1a73e5",
        "b759aed1-f268-405b-90f9-03966227e0bd",
        "4c0d66ce-07b2-457b-97dc-a08297e61bed"
    ]
}



第一步：预览将要删除的数据（安全检查）
请先复制并执行以下 SQL 命令。这个命令不会删除任何数据，只会把满足条件（在北京时间2025年8月5日采集）的记录全部列出来给您看。

SQL

SELECT *
FROM public.raw_events
WHERE
    collected_at::date = '2025-08-05';
执行后，请检查返回的结果是否确实是您想要删除的、collected_at 日期为 2025年8月5日 的所有记录。

第二步：执行删除操作
在您确认第一步预览的数据无误后，再执行下面的 DELETE 命令来真正地删除这些数据。

SQL

DELETE
FROM public.raw_events
WHERE
    collected_at::date = '2025-08-05';


[
  "http://en.wikipedia.org/wiki/Gaza_Strip",
  "http://en.wikipedia.org/wiki/Israel–Hamas_war",
  "http://en.wikipedia.org/wiki/Russo-Ukrainian_War",
  "http://en.wikipedia.org/wiki/Russian_invasion_of_Ukraine",
  "http://en.wikipedia.org/wiki/Russia–Ukraine_border",
  "http://en.wikipedia.org/wiki/Russia–Ukraine_war",
  "http://en.wikipedia.org/wiki/Russia–Ukraine_relations",
  "http://en.wikipedia.org/wiki/Gaza_City", 
  "http://en.wikipedia.org/wiki/Hamas"
  "	http://en.wikipedia.org/wiki/Fatah–Hamas_conflict"
  "http://en.wikipedia.org/wiki/Israeli–Palestinian_conflict"
  "http://en.wikipedia.org/wiki/West_Bank"
  "http://en.wikipedia.org/wiki/Palestinians"
  "http://en.wikipedia.org/wiki/Palestine"
  "http://en.wikipedia.org/wiki/Palestinian_nationalism"
]


