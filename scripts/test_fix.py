#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„ fetch_rich_articles_for_event æ–¹æ³•
"""

import os
import sys
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

def test_fix():
    """æµ‹è¯•ä¿®å¤åçš„æ–¹æ³•"""
    try:
        # ç›´æ¥å¯¼å…¥æˆ‘ä»¬çš„å®¢æˆ·ç«¯
        from scraper.newsapi_client import NewsApiClient
        
        client = NewsApiClient()
        print("âœ… NewsApiClient åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ä¸€ä¸ªå·²çŸ¥çš„äº‹ä»¶URI
        test_event_uri = "eng-10726381"  # ä½¿ç”¨ä¹‹å‰æµ‹è¯•ä¸­è·å–çš„äº‹ä»¶URI
        
        print(f"ğŸ” æµ‹è¯•è·å–äº‹ä»¶ {test_event_uri} çš„æ–‡ç« ...")
        
        articles = client.fetch_rich_articles_for_event(
            event_uri=test_event_uri,
            articles_count=2
        )
        
        if articles:
            print(f"âœ… æˆåŠŸè·å– {len(articles)} ç¯‡æ–‡ç« ")
            print("ğŸ“‹ ç¬¬ä¸€ç¯‡æ–‡ç« ä¿¡æ¯:")
            article = articles[0]
            print(f"  - æ ‡é¢˜: {article.get('title', 'N/A')}")
            print(f"  - æ¥æº: {article.get('source', {}).get('name', 'N/A')}")
            print(f"  - å‘å¸ƒæ—¶é—´: {article.get('dateTimePub', 'N/A')}")
            return True
        else:
            print("âš ï¸ æœªè·å–åˆ°æ–‡ç« ")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_fix()
    if success:
        print("\nğŸ‰ ä¿®å¤éªŒè¯æˆåŠŸï¼")
    else:
        print("\nâŒ ä¿®å¤éªŒè¯å¤±è´¥")
        sys.exit(1) 