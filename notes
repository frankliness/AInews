docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS raw_events (
    id            BIGSERIAL PRIMARY KEY,
    source        VARCHAR(32),
    title         TEXT,
    body          TEXT,
    published_at  TIMESTAMPTZ,
    url           TEXT UNIQUE,
    likes         INT,
    retweets      INT,
    collected_at  TIMESTAMPTZ DEFAULT now()
);
SQL
)"

docker compose exec postgres \
   psql -U airflow -d ainews \
  -c "$(cat <<'SQL'
CREATE TABLE IF NOT EXISTS summaries (
    id          BIGSERIAL PRIMARY KEY,
    raw_id      BIGINT UNIQUE
                REFERENCES raw_events(id) ON DELETE CASCADE,
    summary_cn  TEXT          NOT NULL,
    summary_en  TEXT          NOT NULL,
    created_at  TIMESTAMPTZ   DEFAULT now()
);
SQL
)"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT id, source, left(title,50) AS title_snip, published_at
      FROM raw_events
      ORDER BY id DESC
      LIMIT 3;"


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT COUNT(*) FROM summaries;"

  docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "SELECT raw_id, left(summary_cn,40) AS cn_snip,
              left(summary_en,40) AS en_snip,
              created_at
        FROM summaries
    ORDER BY created_at DESC
       LIMIT 5;"



Â¶ÇÊûú‰Ω†ÊÉ≥ËÆ© ÊâÄÊúâ raw_events ÈáçÊñ∞ËøõÂÖ•ÈòüÂàóÔºåÂè™Ë¶ÅÊääÊï¥‰∏™ summaries Ë°®Ê∏ÖÁ©∫Â∞±Ë°åÔºö


docker compose exec postgres \
  psql -U airflow -d ainews \
  -c "TRUNCATE TABLE summaries RESTART IDENTITY;"


  # Êü•ÁúãÂç∑ÊòØÂê¶Â≠òÂú®
docker volume ls | grep pgadmin-data

# ËøõÂÖ•Âç∑ÁõÆÂΩïÔºàLinux/macOSÔºâ
docker volume inspect pgadmin-data \
  --format '{{ .Mountpoint }}'

# Â§á‰ªΩ pgAdmin ÈÖçÁΩÆÔºàÂèØÈÄâÔºâ
docker run --rm -v pgadmin-data:/data alpine \
  tar -czf - -C /data . > pgadmin_backup_$(date +%F).tgz

# X API token
AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4

curl -X GET "https://api.twitter.com/2/users/by?usernames=cnviolations,reuters,bbcworld \
  -H "Authorization: AAAAAAAAAAAAAAAAAAAAAP3F2wEAAAAAPNnxg%2BkM9yKvujP7EvTvI7LhaYs%3DOQidUwRyYu8NHccBdTQtfPYPbnI1i5hMsU00GctJFW5rhNXJQ4"


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.reuters import ReutersScraper
scraper = ReutersScraper()
raw = scraper.fetch()
items = scraper.parse(raw)
print(f"üîé Reuters fetched {len(items)} items")
for i, it in enumerate(items[:3], 1):
    print(f"\n‚Äî Item {i} ‚Äî")
    print(it)
PY


docker compose exec -T airflow-webserver python - <<'PY'
from scraper.twitter_source import TwitterScraper
scraper = TwitterScraper()
tweets = list(scraper.fetch_all())
print(f"üîé Twitter fetched {len(tweets)} tweets")
for i, tw in enumerate(tweets[:3], 1):
    print(f"\n‚Äî Tweet {i} ‚Äî")
    print(tw.as_dict())
PY
docker compose exec --user root airflow-webserver bash
echo 'export HTTP_PROXY=http://host.docker.internal:1082'  >> /root/.bashrc
echo 'export HTTPS_PROXY=http://host.docker.internal:1082' >> /root/.bashrc
exit



Á≥ªÁªüËßíËâ≤: ‰Ω†ÊòØ‰∏ÄÂêçËµÑÊ∑± Python ÂêéÁ´Ø + Êï∞ÊçÆÂ∑•Á®ãÂ∏àÔºåÊìÖÈïø Airflow„ÄÅLLM API„ÄÅÂêëÈáèÊï∞ÊçÆÂ∫ì„ÄÅÊñá‰ª∂ I/O„ÄÇ

ÁõÆÊ†á: ‰∏∫‰∏≠ÊñáÊó∂ÊîøËá™Â™í‰ΩìÊûÑÂª∫‰∏ÄÊù°‚ÄúÊäì-ÂàÜ-ÈÄâ-ÂÜô‚ÄùËá™Âä®ÈÄâÈ¢òÊµÅÊ∞¥Á∫ø‚Äî‚Äî  
- **‰ªÖÊäìÂèñËøáÂéª 24 Â∞èÊó∂ÁöÑÊñ∞Èóª**  
- **GPT ÁîÑÂà´ + ÂéªÈáç**ÔºöÂêå‰∏Ä‰∫ã‰ª∂‰ªÖÂÜô‰∏ÄÊ¨°ÔºåÈô§ÈùûÂà§ÂÆö‰∏∫‚ÄúÈáçÂ§ßÊõ¥Êñ∞‚Äù  
- **ÊØèÂ§©ËøêË°å 4 Ê¨°**ÔºàUTC+8 ÁöÑ 00:00„ÄÅ06:00„ÄÅ12:00„ÄÅ18:00ÔºâÔºåÊääÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊëòË¶ÅÂÜôÂÖ•Êú¨Âú∞ MarkdownÔºàÊåâÊó•ÊúüËÅöÂêàÔºâ

LANG=zh  # ÊîπÊàê en ÂèØÂàáÊç¢Ëã±Êñá
====================== ÈúÄÊ±ÇËØ¶ÊÉÖÔºàv3Ôºâ ======================
1. **Êï∞ÊçÆÈááÈõÜ (Êäì)**
   - Êñ∞ÈóªÊ∫êÔºöNewsAPI„ÄÅEventRegistry„ÄÅReuters RSS„ÄÅX/Twitter ÊåáÂÆöË¥¶Âè∑„ÄÅÂæÆÂçöÁÉ≠Êêú
   - Airflow DAG `schedule_interval="0 */6 * * *"`ÔºåÊØèÊ¨°‰ªÖÊãâÂèñ `now()-24h` ÂÜÖÁöÑÊñ∞Êñá
   - Áªü‰∏ÄÂ≠óÊÆµ `id, title, body, published_at, source, url, lang, social_metrics`
2. **ÂàùÁ≠õ + ÂéªÈáç (ÂàÜ)**
   - GPT-4o ÂáΩÊï∞Ë∞ÉÁî®ÔºöËøáÊª§Èùû„ÄåÊîøÊ≤ª/ÂÜõ‰∫ã/ÁßëÊäÄ/ÁªèÊµé/ÊñáÂåñ„Äç„ÄÅ>24h„ÄÅÊó†Áã¨ÂÆ∂ÁªÜËäÇ„ÄÅÂØπÁõÆÊ†áÁî®Êà∑Êó†Áî® ÁöÑÊä•Êñá  
   - **ÂéÜÂè≤ÂéªÈáç**  
     1. ÂØπ `title+url` ÁîüÊàê SimHash ‚Üí 80 % Áõ∏‰ººÂç≥Âêå‰∫ã‰ª∂  
     2. Ëã•Êï∞ÊçÆÂ∫ìÂ∑≤ÊúâÊëòË¶ÅÔºåË∞ÉÁî® GPT ËØ¢ÈóÆ _‚ÄúÊòØÂê¶ÈáçÂ§ßÊõ¥Êñ∞ÔºüÔºàÊòØ/Âê¶ + 20 Â≠óÁêÜÁî±Ôºâ‚Äù_  
        - Âê¶ ‚Üí ‰∏¢ÂºÉ  
        - ÊòØ ‚Üí ËßÜ‰∏∫Êñ∞ÊëòË¶ÅÔºåÂÜôÂÖ•Âπ∂Âú® Markdown Âç°ÁâáÊ†áÊ≥®‚Äú„ÄêÊõ¥Êñ∞„Äë‚Äù
3. **ÈáèÂåñÊâìÂàÜ (Âà§)**
   - ÂÖ¨Âºè `score = 0.4*Hot + 0.4*Sim + 0.2*Fresh`  
   - `Hot` = likes + retweets  
   - `Sim` = ‰∏é"Êó∂ÊîøËßÜÈ¢ëË¥¶Âè∑‰∏ªÈ¢òÂêëÈáè"‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÔºàFaissÔºâ  
   - `Fresh` = e^(‚ÄìŒît/24h)  
   - `score > 0.6` ÂÖ•Ê±†
4. **ÊëòË¶ÅÁîüÊàê (ÂÜô)**
   - GPT-4o Few-shot PromptÔºåËæìÂá∫ **JSON**Ôºö
     ```json
     {
       "hashtags": ["#ÂõΩÂÆ∂", "#ËÆÆÈ¢ò"],   // 2-5 ‰∏™#
       "title": "‚â§8 Â≠ó‰∏ªÊ†áÈ¢ò",
       "subtitle": "‚â§12 Â≠óÂâØÊ†áÈ¢ò",
       "summary": "‚ë† ‰∫ã‰ª∂‚Ä¶‚ë° ËÉåÊôØ‚Ä¶‚ë¢ ÁúãÁÇπ‚Ä¶", // ‚â§200 Â≠ó
       "date": "YYYY-MM-DD",
       "source": "Â™í‰Ωì ‚Äì URL",
       "is_update": false           // GPT Âà§Êñ≠ÁöÑÈáçÂ§ßÊõ¥Êñ∞Ê†áËÆ∞
     }
     ```
5. **Êú¨Âú∞ËêΩÁõò (ËæìÂá∫)**
   - Ë∑ØÂæÑ `./summaries/YYYY-MM-DD.md`ÔºåÊØèÊó•ÂçïÊñá‰ª∂ÔºõËã•Â∑≤Â≠òÂú®ÂàôËøΩÂä†  
   - Markdown Ê®°ÊùøÔºö
     ```markdown
     ## {title}ÔΩú{subtitle}{% if is_update %}„ÄêÊõ¥Êñ∞„Äë{% endif %}
     - **{hashtags}**
     - ‚ë† ‚Ä¶ ‚ë° ‚Ä¶ ‚ë¢ ‚Ä¶
     - *Êù•Ê∫êÔºö{source}*
     ```
   - ÁºñÁ†Å UTF-8ÔºåÊó† BOM
6. **ËøêË°åÈ¢ëÊ¨°**  
   - Airflow DAG `news_pipeline.py`Ôºö`0 */6 * * *`ÔºàÂåó‰∫¨Êó∂Èó¥ 00/06/12/18 ÁÇπËß¶ÂèëÔºâ

ÊäÄÊúØÊ†à
-------
- **Python 3.11** Ôºàpoetry ÁÆ°ÁêÜ‰æùËµñÔºâ  
- Airflow 2.9  
- HTTP: httpx + tenacity ÈáçËØï  
- OpenAI SDK ‚â•1.30ÔºàÂáΩÊï∞Ë∞ÉÁî®Ôºâ  
- ÂêëÈáèÂ∫ì: faiss-cpu  
- Âà§Èáç: simhash + Redis Bloom  
- ORM: SQLModel + SQLiteÔºàÊú¨Âú∞ÔºåÂèØÊõøÊç¢ PostgresÔºâ  
- ÂçïÂÖÉÊµãËØï: pytest + GitHub Actions CI  

‰∫§‰ªòÁâ©
------
1. **ÁõÆÂΩïÁªìÊûÑ**

```
Áé∞Âú®ÊÇ®ÂèØ‰ª•ÈÄöËøápgAdminËøûÊé•V2Êï∞ÊçÆÂ∫ìÔºö
ËøûÊé•ÂèÇÊï∞Ôºö
‰∏ªÊú∫: host.docker.internal
Á´ØÂè£: 5434
Êï∞ÊçÆÂ∫ì: ainews
Áî®Êà∑Âêç: airflow
ÂØÜÁ†Å: airflow_pass

ËÆøÈóÆ Phoenix Airflow UI: http://localhost:8082
ÁôªÂΩïÂá≠ÊçÆ:
Áî®Êà∑Âêç: phoenix_admin
ÂØÜÁ†Å: phoenix123
Âú® Phoenix UI ‰∏≠ÊâãÂä®Ëß¶Âèë DAG:
ÊâæÂà∞ phoenix_news_pipeline DAG
ÁÇπÂáª "Trigger DAG" ÊåâÈíÆ

Phoenix Êï∞ÊçÆÂ∫ìËøûÊé•ÂèÇÊï∞Ôºö
ÂèÇÊï∞	ÂÄº
Host	localhost
Port	5434
Database	phoenix_db
Username	phoenix_user
Password	phoenix_pass

‰ΩøÁî®ÊñπÂºè
Âú® Airflow UI ‰∏≠ËÆæÁΩÆ API KeysÔºö
ÁôªÂΩï Airflow UI
ÂØºËà™Âà∞ "Admin" -> "Variables"
ÂàõÂª∫ÂèòÈáè ainews_eventregistry_apikeysÔºåÂÄº‰∏∫ JSON Ê†ºÂºèÔºö
{
    "keys": [
        "b03b250a-97ec-4dd0-905e-a038eb1a73e5",
        "b759aed1-f268-405b-90f9-03966227e0bd",
        "4c0d66ce-07b2-457b-97dc-a08297e61bed"
    ]
}